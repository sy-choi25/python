{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fdc62dc",
   "metadata": {},
   "source": [
    "Seq2Seq(Sequence-to-Sequence)\n",
    "* 순서\n",
    "[원문 문장] → [Encoder] → [Context Vector] → [Decoder] → [출력 문장]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddde5a8",
   "metadata": {},
   "source": [
    "<span style=\"color: Gold\"> 1. 학습용 영어-프랑스어 병렬 문장 데이터 준비\n",
    "\n",
    "개념:   \n",
    "입력(영어)과 출력(프랑스어) 쌍으로 구성  \n",
    "디코더 입력에는 시작 토큰(\\t), 타겟에는 종료 토큰(\\n) 추가  \n",
    "\n",
    "설명:  \n",
    "input_texts: 인코더에 입력될 영어 문장  \n",
    "target_texts: 디코더가 생성해야 할 프랑스어 문장 (전처리 포함)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d65f0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: Hello               --> 타겟:\tBonjour\n",
      "\n",
      "입력: How are you         --> 타겟:\tComment allez-vous\n",
      "\n",
      "입력: Good morning        --> 타겟:\tBonjour matin\n",
      "\n",
      "입력: Thank you           --> 타겟:\tMerci\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "data_pairs = [\n",
    "    (\"Hello\", \"Bonjour\"),\n",
    "    (\"How are you\", \"Comment allez-vous\"),\n",
    "    (\"Good morning\", \"Bonjour matin\"),\n",
    "    (\"Thank you\", \"Merci\"),\n",
    "]\n",
    "\n",
    "# 입력과 타겟을 분리\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "for eng,fra in data_pairs:\n",
    "    input_texts.append(eng)\n",
    "    # 디코더 입력 '\\t'(시작), 디코더 출력: '\\n' (종료)\n",
    "    target_texts.append(f'\\t{fra}\\n')\n",
    "for i in range(len(input_texts)):\n",
    "    print(f'입력: {input_texts[i]:20s}--> 타겟:{target_texts[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494cb26d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<span style=\"color: Gold\"> 2. 문자 단위 사전(vocabulary) 생성 및 정수 인덱스 변환  \n",
    "\n",
    " 개념:  \n",
    "각 문자를 고유한 정수로 매핑  \n",
    "입력과 타겟의 사전은 별도 관리   \n",
    "원-핫 인코딩으로 신경망 입력 형태 생성  \n",
    "\n",
    "설명:  \n",
    "input_characters: 영어 문장에 등장하는 모든 고유 문자  \n",
    "target_characters: 프랑스어 문장 + 특수 토큰(\\t, \\n)  \n",
    "encoder_input_data: 3D 배열 (샘플, 시퀀스 길이, 문자 사전 크기)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b1814b",
   "metadata": {},
   "source": [
    "문자를 숫자 인덱스로 바꾸기 위한 매핑 테이블을 만드는 것  \n",
    "-> 문자열 데이터 → 문자 집합 추출 → 인덱스 부여 → 인코딩 준비  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e1c6f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "고유 입력 문자수: 19\n",
      "고유타겟 입력 문자수 : 22\n",
      "최대 입력 문자길이 : 12\n",
      "최대 타겟 문자길이 : 20\n",
      "# 샘플 시퀀스길이, 문자 사전 크기\n",
      "endocer_input_sdate :(4, 12, 19)\n",
      "decoder_input_data.shap : (4, 20, 22)\n",
      "decoder_target_data.shape : (4, 20, 22)\n"
     ]
    }
   ],
   "source": [
    "# 입력과 타겟의 고유한 문자 수집\n",
    "# input_characters = set()\n",
    "# target_characters = set()\n",
    "\n",
    "# for text in input_texts:\n",
    "#     for char in text:\n",
    "#         input_characters.add(char)\n",
    "\n",
    "# 문자 집합 만들기\n",
    "# 단어 하나하나를 집합으로 만드는 것\n",
    "# 입력 문자 집합 (input_characters) = {H, e, l, o, w}\n",
    "# 출력 문자 집합 (target_characters) = {B, o, n, j, u, r, S, a, l, t}\n",
    "# { }은 set이 자동으로 실행되어 중복은 제거된 상태\n",
    "input_characters = {char for text in input_texts for char in text }\n",
    "target_characters = {char for target_text in target_texts for char in target_text}\n",
    "\n",
    "# 정렬해서 일관성 확보\n",
    "# 각각 집합 내부에서 일관성 확보\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "\n",
    "# 토큰(문자)개수 계산\n",
    "# 집합의 길이에 따라 원핫 벡터 차원을 결정하기 위해서. 문자 집합이 5개면 원핫 벡터 길이 5차원이 필요\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "\n",
    "# 가장 긴 문장 길이 계산\n",
    "# 시퀀스 길이가 달라도, 뱅ㄹ 크기는 고정해서 LSTM에 넣을 수 잇음\n",
    "# 짧은 문장은 0-padding을 사용\n",
    "# 모든 문장을 같은 길이로 맞춤\n",
    "# 가장 긴 문장 길이에 맞춰 패딩 기준을 맞추기 위해 하는 작업\n",
    "max_encoder_seq_length = max(len(txt) for txt in input_texts)\n",
    "max_decoder_seq_length = max(len(txt) for txt in target_texts)\n",
    "\n",
    "# 문자 -> 인덱스 매핑\n",
    "# 문자의 순서대로 인덱스를 부여하여 문자와 그 번호가 매칭되도록 딕셔너리를 만들어줌\n",
    "# 문자: 인덱스 숫자번호 -> 딕셔너리 형태로 만듦\n",
    "input_token_index = { char:i for i,char in enumerate(input_characters)}\n",
    "target_token_index = { char:i for i,char in enumerate(target_characters)}\n",
    "\n",
    "# 인덱스 -> 문자로 역매핑(추론시 사용)\n",
    "# 예측한 숫자를 다시 문자로 바꾸는 과정\n",
    "# 인덱스 숫자번호 : 문자 로 만드는 방법 -> key로는 추적이 안되기 때문에 필요\n",
    "reverse_input_token_index = {idx:char for char,idx in input_token_index.items()}\n",
    "reverse_target_token_index = {idx:char for char,idx in target_token_index.items()}\n",
    "\n",
    "# encoder_input_data = 3D배열 (샘플, 시퀀스 길이, 문자 사전 크기)\n",
    "# Encoder 입력용 -> 각 시퀀스의 문자를 원-핫 벡터로 표현\n",
    "encoder_input_data = np.zeros((len(input_texts),max_encoder_seq_length,num_encoder_tokens),\n",
    "                              dtype = 'float32')\n",
    "# Decoder 입력용-> 매 시점(t)에 이전 실제 출력(정답) 문자 토큰을 넣어 모델이 학습하도록 함\n",
    "decoder_input_data = np.zeros((len(input_texts),max_decoder_seq_length,num_decoder_tokens),\n",
    "                              dtype = 'float32')\n",
    "# Decoder 정답용 -> 한 타임스텝 뒤로 밀린 정답\n",
    "                    # 예: decoder_input_data: \\t b o n j o u r\n",
    "                    # decoder_target_data: b o n j o u r \\n\n",
    "                    # LSTM이 다음 시점 출력(y_t)과 비교하며 학습\n",
    "decoder_target_data = np.zeros((len(input_texts),max_decoder_seq_length,num_decoder_tokens),\n",
    "                              dtype = 'float32')\n",
    "\n",
    "# 문자별로 원핫 인코딩\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    # 1) encoder 입력\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0 # (샘플, 시퀀스 길이, 입력 문자 수)/ i번째 샘플, t번재 시점에서 문자 char를 원핫인코딩\n",
    "    # 2) Decoder 입력 & 정답\n",
    "    for t, char in enumerate(target_text):\n",
    "       #'decoder_input_data: 전체 타겟 시퀀스 (시작 토큰 포함)'\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0  # (샘플, 시퀀스 길이, 출력 문자 수)/ target_text 전체 문장을 t 시점마다 원-핫 인코딩\n",
    "\n",
    "       #'decoder_target_data: 한 타임스텝 앞선 정답 (Teacher Forcing용)'\n",
    "        if t > 0:   # 첫번째 입력을 제외하고 \n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0   # 시점 개념이 아닌 타겟의 관점에서 input보다 하나 짧은거 가져와! 그래서 t-1인 거 같은 t가 시퀀스 길이니까\n",
    "        # = 1.0  이라는 것은 원핫인코딩에서 가면 1 나다라는 0으로 하는 것처럼, 이 지점이 1이야 라는 의미\n",
    "print(f'고유 입력 문자수: {num_encoder_tokens}')\n",
    "print(f'고유타겟 입력 문자수 : {num_decoder_tokens}')\n",
    "print(f'최대 입력 문자길이 : {max_encoder_seq_length}')\n",
    "print(f'최대 타겟 문자길이 : {max_decoder_seq_length}')\n",
    "print(f'# 샘플 시퀀스길이, 문자 사전 크기')\n",
    "print(f'endocer_input_sdate :{encoder_input_data.shape}')\n",
    "print(f'decoder_input_data.shap : {decoder_input_data.shape}')\n",
    "print(f'decoder_target_data.shape : {decoder_target_data.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4456ba5",
   "metadata": {},
   "source": [
    "<span style=\"color: Gold\"> 3. LSTM 기반 Seq2Seq 인코더-디코더 학습 모델 구축\n",
    "\n",
    " 개념:    \n",
    "    Encoder: 입력 시퀀스를 처리하고 최종 상태(h, c) 출력  \n",
    "    Decoder: Encoder 상태를 초기값으로 받아 타겟 시퀀스 생성  \n",
    "    return_state=True: LSTM 내부 상태(h, c) 반환  \n",
    "    return_sequences=True: 모든 타임스텝 출력  \n",
    "\n",
    "설명:\n",
    "    encoder_states: [h, c] (hidden state, cell state)  \n",
    "    decoder_lstm: 초기 상태로 encoder_states 전달  \n",
    "    decoder_dense: Softmax로 각 타임스텝의 문자 확률 분포 생성  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fd1a31",
   "metadata": {},
   "source": [
    "<span style=\"font-size:12px;\">\n",
    "\n",
    "<span style=\"color: lightblue;\"> LSTM 구조\n",
    "\n",
    "- LSTM(Long Short-Term Memory)은 RNN 계열의 한 종류로, 시퀀스를 처리하면서 장기 의존성을 기억할 수 있도록 설계된 구조  \n",
    "<br>\n",
    "- Hidden state (h_t)\n",
    "    - 현재 시점(t)에서 LSTM이 계산한 출력 벡터\n",
    "    - 다음 시점으로 전달되며, 동시에 외부에서 바로 읽어서 사용할 수도 있음\n",
    "\n",
    "- Cell state (c_t)\n",
    "    - 시퀀스 전체의 장기 기억(Long-term memory) 역할\n",
    "    - 정보를 선택적으로 기억하거나 잊게 함 (forget gate, input gate, output gate가 제어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7905b9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 모델 구조:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"seq2seq_training\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"seq2seq_training\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">282,624</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>) │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">285,696</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_dense       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">5,654</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m282,624\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m) │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m285,696\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_dense       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m)  │      \u001b[38;5;34m5,654\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">573,974</span> (2.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m573,974\u001b[0m (2.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">573,974</span> (2.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m573,974\u001b[0m (2.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "latent_dim = 256  # LSTM 은닉 차원 (내부 표현 크기)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# ==================== Encoder ====================\n",
    "# 인풋레이어 생성\n",
    "# encoder_inputs: (배치 크기, 시퀀스 길이, 입력 문자 수)\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens), name='encoder_input')\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# encoder_outputs는 사용하지 않고, 내부 상태(state_h, state_c)만 디코더로 전달\n",
    "# 입력 시퀀스를 LSTM에 통과시켜서 마지막 은닉상태(state_h)와 셀상태(state_c)를 받아서\n",
    "# 두 상태는 입력 문장의 의미(context)를 압축한 벡터\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# ==================== Decoder ====================\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name='decoder_input')\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "\n",
    "# 디코더 초기 상태로 인코더 최종 상태 사용 (컨텍스트 전달)\n",
    "# 인코더의 상태 (state_h, state_c)를 초기상태로 받아서 자신의 입력 decoder_inputs 을 기반으로\n",
    "# 다음단어를 예측 --> 각 시점의 출력은 Dense+softmax를 거쳐서 단어(문자) 확률분포\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# 각 타임스텝에서 문자 확률 분포 생성\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# ==================== 학습 모델 ====================\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='seq2seq_training')\n",
    "\n",
    "print(\"\\n 모델 구조:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfc51a1",
   "metadata": {},
   "source": [
    " <span style=\"color: Gold\"> 4. 목적: Seq2Seq 모델 컴파일 및 학습 실행   \n",
    "\n",
    " 개념:  \n",
    "    - categorical_crossentropy: 다중 클래스(문자 사전) 손실  \n",
    "    - Teacher Forcing: decoder_input_data는 정답 시퀀스 전체 제공  \n",
    "    - 학습 목표: decoder_target_data (한 타임스텝 앞당긴 정답)  \n",
    "\n",
    " 설명:  \n",
    "    - optimizer='rmsprop': 순환신경망에 안정적인 최적화 알고리즘  \n",
    "    - epochs=100: 작은 데이터셋이므로 충분한 반복 필요  \n",
    "    - batch_size=2: 메모리 효율 (실제로는 전체 4개 샘플 사용)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc6380f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'rmsprop',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    [encoder_input_data,decoder_input_data],  # seq2seq\n",
    "    decoder_target_data,\n",
    "    batch_size = 2,\n",
    "    epochs = 500,\n",
    "    # vallidation_split = 0.0,  # 데이터셋이 작아서 분할 안함\n",
    "    verbose = 0 # 0 출력안하고 1은 간단하게 2 좀더 출\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9194e6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48750001192092896"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['accuracy'][-1]\n",
    "# model.save_weigts('seq2seq_weight.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f613bc",
   "metadata": {},
   "source": [
    "<span style=\"color: Gold\">  5. 학습된 가중치를 사용해 실제 번역용 추론 모델 구축\n",
    "\n",
    "핵심 개념:  \n",
    "Encoder 모델: 입력 → 내부 상태 추출  \n",
    "Decoder 모델: 이전 상태 + 현재 입력 → 다음 문자 예측  \n",
    "추론 시에는 Teacher Forcing 없이 자기 예측을 다음 입력으로 사용  \n",
    "\n",
    "설명:    \n",
    "encoder_model: 입력 문장 → [h, c] 상태 출력  \n",
    "decoder_model: 한 타임스텝씩 반복 실행  \n",
    "각 스텝에서 가장 높은 확률의 문자 선택 (Greedy Decoding)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea957ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder 추론모델\n",
    "encoder_model = Model(encoder_inputs, encoder_states, name = 'encoder_inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a841e7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder 추론모델\n",
    "# 이전 타임스텝의 상태를 입력으로 받음\n",
    "decoder_state_input_h = Input(shape=(latent_dim,), name = 'decoder_state_h')\n",
    "decoder_state_input_c = Input(shape=(latent_dim,), name = 'decoder_state_c')\n",
    "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# LSTM실행(이전상태 + 현재입력)\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_state_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "# 문자 확률 분포 생성\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_state_inputs,\n",
    "    [decoder_outputs] + decoder_states,\n",
    "    name = 'decoder_inference'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa71b1f7",
   "metadata": {},
   "source": [
    "<span style=\"color: Gold\">  6. 입력 문장을 번역하는 디코딩 함수 구현 및 테스트\n",
    "\n",
    " 개념:  \n",
    "    - Greedy Decoding: 매 스텝 가장 높은 확률 문자 선택  \n",
    "    - 종료 조건: '\\n' 토큰 생성 또는 최대 길이 도달  \n",
    "    - 자기회귀적 생성: 이전 예측을 다음 입력으로 반복 사용  \n",
    "\n",
    " 설명:  \n",
    "    1. Encoder로 입력 문장의 상태 벡터 추출  \n",
    "    2. 시작 토큰('\\t')으로 Decoder 시작  \n",
    "    3. 반복: 현재 문자 예측 → 다음 입력으로 사용  \n",
    "    4. '\\n' 만나면 종료  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96cdf628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    \"\"\"\n",
    "    입력 시퀀스(원-핫 인코딩)를 받아 번역된 문자열 반환\n",
    "    \"\"\"\n",
    "    # 1단계: Encoder로 상태 벡터 추출\n",
    "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "    \n",
    "    # 2단계: 디코더 시작 토큰 준비 ('\\t')\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.0\n",
    "    \n",
    "    # 3단계: 문자를 하나씩 생성\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        # 현재 문자 예측 + 다음 상태 업데이트\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value, verbose=0\n",
    "        )\n",
    "        \n",
    "        # 가장 높은 확률의 문자 선택 (Greedy)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_token_index[sampled_token_index]\n",
    "        \n",
    "        # 문자 추가\n",
    "        decoded_sentence += sampled_char\n",
    "        \n",
    "        # 종료 조건 체크\n",
    "        if sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "        \n",
    "        # 다음 스텝 준비: 현재 예측을 다음 입력으로\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "        \n",
    "        # 상태 업데이트\n",
    "        states_value = [h, c]\n",
    "    \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d952f374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력문장 : Hello\n",
      "정답문장 : Bonjour\n",
      "모델 예측 : Bonjour\n",
      "----------------------------------------------------------------------------------------------------\n",
      "입력문장 : How are you\n",
      "정답문장 : Comment allez-vous\n",
      "모델 예측 : Comment allllz\n",
      "----------------------------------------------------------------------------------------------------\n",
      "입력문장 : Good morning\n",
      "정답문장 : Bonjour matin\n",
      "모델 예측 : Bonjour maaii\n",
      "----------------------------------------------------------------------------------------------------\n",
      "입력문장 : Thank you\n",
      "정답문장 : Merci\n",
      "모델 예측 : Merci\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for seq_index in range(len(input_texts)):\n",
    "    # 원핫인코딩 입력 추출\n",
    "    input_seq =  encoder_input_data[seq_index:seq_index+1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    \n",
    "    # 시작/종료 토큰 제거\n",
    "    decoded_sentence = decoded_sentence.replace('\\t','').replace('\\n','')\n",
    "    print(f'입력문장 : {input_texts[seq_index]}')\n",
    "    print(f'정답문장 : {target_texts[seq_index][1:-1]}')  # 시작 종료토큰제거\n",
    "    print(f'모델 예측 : {decoded_sentence}')\n",
    "    print('-'*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533a8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2966bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
