{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1982b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 머신러닝 기반 감정분석\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3288555a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 50, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from textblob import  TextBlob\n",
    "from afinn import Afinn\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# nltk 데이터 다운로드\n",
    "nltk.download('movie_reviews', quiet=True)\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "# 영화 리뷰 데이터 로드\n",
    "fileids = movie_reviews.fileids()\n",
    "reviews = [movie_reviews.raw(fileid) for fileid in fileids[:50]] + [movie_reviews.raw(fileid) for fileid in fileids[-50:]]\n",
    "categories = [movie_reviews.categories(fileid)[0] for fileid in fileids[:50]] +[movie_reviews.categories(fileid)[0] for fileid in fileids[-50:]]\n",
    "len(reviews), categories.count('pos'), categories.count('neg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4697c49",
   "metadata": {},
   "source": [
    "<span style=\"color: Gold\"> 1. 나이브 베이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799bd577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이브 베이즈\n",
    "# 베이즈 정리\n",
    "# '좋다' 단어를 본 후 이 리뷰가 긍정일 확률\n",
    "# P( 긍정 | 좋다 ) = P( 좋다 | 긍정) X P(긍정) / P(좋다)\n",
    "# -> 전체 리뷰에서 좋다가 나올 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "599aac0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 분할\n",
    "#x_train, x_test, y_train, y_test = train_test_split(reviews, categories, test_size=0.2,random_state=42, stratify=categories) # 아래 절차이나 다른 방식으로 표현\n",
    "dataset = train_test_split(reviews, categories, test_size=0.2,random_state=42, stratify=categories)\n",
    "\n",
    "len(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f4e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf 벡터화\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "x_train = vectorizer.fit_transform(dataset[0])\n",
    "x_test = vectorizer.transform(dataset[1])\n",
    "\n",
    "y_train = dataset[2]\n",
    "y_test = dataset[3]\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6746771c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.54      0.70      0.61        10\n",
      "         pos       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.55      0.55      0.54        20\n",
      "weighted avg       0.55      0.55      0.54        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. mnb\n",
    "mnb_clf = MultinomialNB()\n",
    "mnb_clf.fit(x_train, y_train)\n",
    "predict = mnb_clf.predict(x_test)\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f32ed3",
   "metadata": {},
   "source": [
    "<span style=\"color: Gold\">  2. Logiscticregression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9679588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.54      0.70      0.61        10\n",
      "         pos       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.55      0.55      0.54        20\n",
      "weighted avg       0.55      0.55      0.54        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Logiscticregression\n",
    "\n",
    "logi = LogisticRegression()\n",
    "logi.fit(x_train,y_train)\n",
    "predict_logi = logi.predict(x_test)\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d2cdae",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa615a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능향상\n",
    "    # 소문자변환 - 연속된 문자열 중에 3글자 이상인 것만 가져오기 - 어간추출(형태소분석) - 불용어제거\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e16da5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 전처리\n",
    "def custom_tokenizer(text):\n",
    "    text = text.lower()     # 소문자 변환\n",
    "    tokenizer = RegexpTokenizer(r\"[\\w']{3,}\")   # 단어 문자(알파벳, 숫자, _)와 작은따옴표(')가 섞여서 3글자 이상 연속되는 모든 문자열을 찾아라\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    porter = PorterStemmer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [porter.stem(token) for token in tokens if token not in stop_words]\n",
    "vector = TfidfVectorizer(\n",
    "    tokenizer  = custom_tokenizer\n",
    "    ,max_features=1000\n",
    "    ,min_df=5\n",
    "    ,max_df=0.5\n",
    "    ,token_pattern = r\"[\\w']{3,}\"\n",
    ")\n",
    "x_train = vector.fit_transform(dataset[0])\n",
    "x_test = vector.transform(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5244c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):    \n",
    "    model.fit(x_train,y_train)\n",
    "    predict = model.predict(x_test)\n",
    "    print(classification_report(y_test, predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3ea0ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.80      0.80      0.80        10\n",
      "         pos       0.80      0.80      0.80        10\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.80      0.80      0.80        20\n",
      "weighted avg       0.80      0.80      0.80        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9caca98",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
