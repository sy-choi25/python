import os
import warnings
from dotenv import load_dotenv

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.retrievers import TavilySearchAPIRetriever
from langchain_core.documents import Document

warnings.filterwarnings("ignore")
load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("OPENAI_API_KEY ì—†ìŒ! .env í™•ì¸í•´ì¤˜")

TAVILY_API_KEY = os.getenv("TAVILY_API_KEY") 

# ë²¡í„°DB ë¡œë“œ
embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")
vectorstore = Chroma(
    persist_directory="./chroma_startup_all",
    collection_name="startup_all_rag",
    embedding_function=embedding_model,
)

try:
    all_data = vectorstore.get()
    ids = all_data.get("ids", [])
    print(f"âœ… ë²¡í„°DB ë¡œë“œ ì™„ë£Œ / ì´ ë²¡í„° ê°œìˆ˜: {len(ids)}")
except Exception as e:
    print("âš  ë²¡í„°DB ìƒíƒœ í™•ì¸ ì¤‘ ì—ëŸ¬:", e)

# LLM
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# ========================================
# í”„ë¡¬í”„íŠ¸ ì •ì˜
# ========================================

# ê´€ë ¨ì„± ê²€ì¦ í”„ë¡¬í”„íŠ¸
relevance_check_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ë¬¸ì„œì™€ ì§ˆë¬¸ì˜ ê´€ë ¨ì„±ì„ ì—„ê²©í•˜ê²Œ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ì§ˆë¬¸]
{question}

[ê²€ìƒ‰ëœ ë¬¸ì„œ ìƒ˜í”Œ]
{documents}

[íŒë‹¨ ê¸°ì¤€]
1. ì§ˆë¬¸ì˜ í•µì‹¬ ì£¼ì œì™€ ë¬¸ì„œì˜ ë‚´ìš©ì´ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ë˜ëŠ”ê°€?
2. ë¬¸ì„œê°€ ì§ˆë¬¸ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ”ê°€?
3. ë‹¨ìˆœíˆ ìœ ì‚¬í•œ ë‹¨ì–´ê°€ ìˆëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì‹¤ì œ ë‹µë³€ ê°€ëŠ¥í•œ ë‚´ìš©ì¸ê°€?

[ì˜ˆì‹œ]
- "ì„œìš¸ ë™ë¬¼ë³‘ì›" vs "ì„œìš¸ ì°½ì—… ê³µê°„" â†’ ê´€ë ¨ì—†ìŒ (ì„œìš¸ë§Œ ê³µí†µ)
- "AI êµìœ¡" vs "ì°½ì—… êµìœ¡" â†’ ê´€ë ¨ì—†ìŒ (êµìœ¡ë§Œ ê³µí†µ, ì£¼ì œ ë‹¤ë¦„)
- "ì°½ì—… ì§€ì›ì‚¬ì—…" vs "ì°½ì—… ìê¸ˆ ì§€ì›" â†’ ê´€ë ¨ìˆìŒ (ì§ì ‘ ì—°ê´€)

ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë‹µë³€: "ê´€ë ¨ìˆìŒ" ë˜ëŠ” "ê´€ë ¨ì—†ìŒ"

ë‹µë³€:""")

# Query Transformation
qt_prompt = ChatPromptTemplate.from_template("""
ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì„ ë²¡í„° ê²€ìƒ‰ì— ì í•©í•œ 'í•µì‹¬ í‚¤ì›Œë“œ ì¤‘ì‹¬ ë¬¸ì¥'ìœ¼ë¡œ ë°”ê¾¸ì„¸ìš”.
ë¶ˆí•„ìš”í•œ ë§ì€ ì œê±°í•˜ê³ , í•µì‹¬ ì¡°ê±´ë§Œ ë‚¨ê¸°ì„¸ìš”.

ì›ë³¸ ì§ˆë¬¸: {question}

ë³€í™˜ëœ ê²€ìƒ‰ìš© ë¬¸ì¥:""")

# ë©€í‹°ì¿¼ë¦¬ ìƒì„±
multi_query_prompt = ChatPromptTemplate.from_template("""
ë‹¤ìŒì§ˆë¬¸ì— ëŒ€í•´ 3ê°€ì§€ ë‹¤ë¥¸ ê´€ì ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”.
ê°ì¿¼ë¦¬ëŠ” ì„¸ ì¤„ë¡œ êµ¬ë¶„í•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”        
ë²ˆí˜¸ë‚˜ ì„¤ëª… ì—†ì´ ì¿¼ë¦¬ë§Œ ì¶œë ¥í•˜ì„¸ìš”

ì›ë³¸ì§ˆë¬¸: {question}""")

# ê¸°ë³¸ RAG í”„ë¡¬í”„íŠ¸
rag_prompt = ChatPromptTemplate.from_messages([
    ("system", """
ë‹¹ì‹ ì€ ì˜ˆë¹„Â·ì´ˆê¸° ì°½ì—…ìë¥¼ ë„ì™€ì£¼ëŠ” 'ì°½ì—… ì§€ì› í†µí•© AI ì–´ì‹œìŠ¤í„´íŠ¸'ì…ë‹ˆë‹¤.

[ì‚¬ìš© ê°€ëŠ¥í•œ ì •ë³´ ìœ í˜•]
- ì§€ì›ì‚¬ì—… ê³µê³  (announcement)
- ì‹¤íŒ¨/ì¬ë„ì „ ì‚¬ë¡€ (cases)
- ì°½ì—… ê³µê°„ ì •ë³´ (space)
- ë²•ë ¹: ì¤‘ì†Œê¸°ì—…ì°½ì—… ì§€ì›ë²• ë“± (law)
- í†µê³„, ë§¤ë‰´ì–¼ ë“± ì°¸ê³  ìë£Œ

[ë‹µë³€ ì›ì¹™]
1. ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ë§¥(Context) ì•ˆì˜ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
2. ë¬¸ë§¥ì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  ì†”ì§í•˜ê²Œ ë§í•˜ì„¸ìš”.
3. ì§ˆë¬¸ ì„±ê²©ì— ë”°ë¼ ë‹¤ìŒ ì •ë³´ ìœ í˜•ì„ ìš°ì„  í™œìš©í•˜ì„¸ìš”.
   - ì§€ì›ì‚¬ì—…Â·ì‹ ì²­ ê°€ëŠ¥ ì—¬ë¶€ â†’ announcement
   - ë²•ì  ì •ì˜Â·ìê²© ìš”ê±´ â†’ law
   - ì¡°ì–¸Â·ì£¼ì˜ì  â†’ cases
   - ê³µê°„Â·ì…ì£¼ â†’ space
4. í•µì‹¬ ë‹µë³€ í›„ í•„ìš”í•˜ë©´ bulletë¡œ ì •ë¦¬í•˜ì„¸ìš”.
5. ë§ˆì§€ë§‰ì— ì°¸ê³  ê·¼ê±° ìœ í˜•ì„ ìš”ì•½í•˜ì„¸ìš”.
"""),
    ("human", "[ë¬¸ë§¥]\n{context}\n\n[ì§ˆë¬¸]\n{question}\n\n[ë‹µë³€]")
])

# ë²•ë ¹ ì „ìš© í”„ë¡¬í”„íŠ¸
law_prompt = ChatPromptTemplate.from_messages([
    ("system", """
ë‹¹ì‹ ì€ ì¤‘ì†Œê¸°ì—…ì°½ì—… ì§€ì›ë²•ì„ ë°”íƒ•ìœ¼ë¡œ ì°½ì—… ì œë„ì™€ ìš”ê±´ì„ ì„¤ëª…í•˜ëŠ” AIì…ë‹ˆë‹¤.

[ê·œì¹™]
1. ë°˜ë“œì‹œ ë¬¸ë§¥ì— ìˆëŠ” ë²•ë ¹ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
2. ê°€ëŠ¥í•˜ë©´ ì¡°ë¬¸ ë²ˆí˜¸(ì œâ—‹ì¡°)ë¥¼ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”.
3. ë¬¸ë§¥ì— ì—†ëŠ” ë‚´ìš©ì€ "ì œê³µëœ ë²•ë ¹ ë¬¸ì„œì—ì„œ í•´ë‹¹ ë‚´ìš©ì€ í™•ì¸ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."ë¼ê³  ë‹µí•˜ì„¸ìš”.
4. ë‹µë³€ ëì— "â€» ë³¸ ë‹µë³€ì€ ì¼ë°˜ ì •ë³´ ì œê³µì´ë©°, êµ¬ì²´ì ì¸ ë²•ë¥  ìë¬¸ì€ ì•„ë‹™ë‹ˆë‹¤."ë¥¼ í¬í•¨í•˜ì„¸ìš”.
"""),
    ("human", "[ë²•ë ¹ ë¬¸ë§¥]\n{context}\n\n[ì§ˆë¬¸]\n{question}\n\n[ì„¤ëª…]")
])

# ì§€ì›ì‚¬ì—… ì¶”ì²œ í”„ë¡¬í”„íŠ¸
recommend_prompt = ChatPromptTemplate.from_messages([
    ("system", """
ë‹¹ì‹ ì€ ì˜ˆë¹„Â·ì´ˆê¸° ì°½ì—…ìì—ê²Œ ê°€ì¥ ì í•©í•œ 'ì§€ì›ì‚¬ì—…ì„ ì¶”ì²œí•˜ëŠ” ì „ë¬¸ê°€ AI'ì…ë‹ˆë‹¤.

[ëª©í‘œ]
ì‚¬ìš©ìì˜ ì¡°ê±´(ë‚˜ì´, ì§€ì—­, ì—…ì¢…, ì°½ì—… ë‹¨ê³„ ë“±)ì„ ê¸°ì¤€ìœ¼ë¡œ
'ì‹¤ì§ˆì ì¸ ë„ì›€ì´ ë˜ëŠ” ì‚¬ì—…(ìê¸ˆÂ·ê³µê°„Â·R&DÂ·ì‹œì œí’ˆÂ·êµìœ¡)'ì„ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.

[ì¶”ì²œ ìš°ì„ ìˆœìœ„]
1. í˜„ê¸ˆì„± ì§€ì›(ì‚¬ì—…í™” ìê¸ˆ, ì‹œì œí’ˆ ì œì‘ë¹„, R&D)
2. ì…ì£¼ ê³µê°„, ì¥ë¹„ ì§€ì›
3. ì—‘ì…€ëŸ¬ë ˆì´íŒ…, ë©˜í† ë§
4. ë‹¨ìˆœ êµìœ¡/íŠ¹ê°•ì€ ë§ˆì§€ë§‰ ìˆœìœ„

[ì¶”ì²œ ê·œì¹™]
1. ë°˜ë“œì‹œ announcement ë¬¸ì„œë§Œ ì‚¬ìš©
2. ì‚¬ìš©ì ì¡°ê±´ê³¼ 'ì§€ì—­Â·ì—°ë ¹Â·ë‹¨ê³„Â·ì—…ì¢…'ì´ ëª…í™•íˆ ë§ëŠ” ê²ƒë§Œ ì¶”ì²œ
3. ìµœëŒ€ 2ê°œê¹Œì§€ë§Œ ì¶”ì²œ
4. ì¡°ê±´ì´ ë§ëŠ” ì‚¬ì—…ì´ ì—†ìœ¼ë©´ ì†”ì§í•˜ê²Œ ë§í•˜ê¸°
5. ITÂ·ì„œë¹„ìŠ¤ì—…ì´ë©´ 'ê¸°ìˆ Â·ì½˜í…ì¸ Â·í”Œë«í¼' í‚¤ì›Œë“œ í¬í•¨ ì‚¬ì—… ìš°ì„ 

[ì¶œë ¥ í˜•ì‹]
â–  ì¶”ì²œ ì‚¬ì—…ëª…
â–  ì™œ ì´ ì‚¬ìš©ìì—ê²Œ ì í•©í•œì§€
â–  ì§€ì› ë‚´ìš©(ìê¸ˆ/ê³µê°„/êµìœ¡ ì¤‘ ë¬´ì—‡ì¸ì§€ ëª…í™•íˆ)
â–  ì‹ ì²­ ëŒ€ìƒ ìš”ì•½
â–  ì ‘ìˆ˜ ê¸°ê°„
â–  ì£¼ì˜ì‚¬í•­

ë§ˆì§€ë§‰ ì¤„: [ì°¸ê³ : ì§€ì›ì‚¬ì—… ê³µê³ ]
"""),
    ("human", "[ì§€ì›ì‚¬ì—… ë¬¸ë§¥]\n{context}\n\n[ì‚¬ìš©ì ì¡°ê±´]\n{question}\n\nìœ„ í˜•ì‹ì— ë§ì¶° ì¶”ì²œí•´ ì£¼ì„¸ìš”.")
])

# Fallback í”„ë¡¬í”„íŠ¸
fallback_prompt = ChatPromptTemplate.from_template("""
ì§ˆë¬¸: {question}

ë‚´ë¶€ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.
ì¼ë°˜ì ì¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë‹µë³€:""")

# ì²´ì¸ ìƒì„±
qt_chain = qt_prompt | llm | StrOutputParser()
multi_query_chain = multi_query_prompt | llm | StrOutputParser()
relevance_chain = relevance_check_prompt | llm | StrOutputParser()
fallback_chain = fallback_prompt | llm | StrOutputParser()


# ========================================
# í—¬í¼ í•¨ìˆ˜
# ========================================

def choose_prompt(question: str):
    """ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¼ ì ì ˆí•œ í”„ë¡¬í”„íŠ¸ ì„ íƒ"""
    recommend_keywords = ["ì¶”ì²œ", "ë§ëŠ”", "ì‹ ì²­í•  ìˆ˜ ìˆëŠ”", "ì§€ì›í•´ì£¼ëŠ”", 
                         "ì‚¬ì—… ì•Œë ¤ì¤˜", "í˜œíƒ", "ì§€ì›ê¸ˆ", "ì§€ì›ì‚¬ì—…"]
    law_keywords = ["ì •ì˜", "ìê²©", "ìš”ê±´", "ì§€ì›ë²•", "ë²•ì—ì„œ", "ë²•ìƒ", "ì œë„"] #ì‹œí–‰,ê·œì •
    
    if any(k in question for k in recommend_keywords):
        return recommend_prompt, "recommend_prompt"
    if any(k in question for k in law_keywords):
        return law_prompt, "law_prompt"
    return rag_prompt, "rag_prompt"


def format_docs(docs):
    """ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
    if not docs:
        return ""
    formatted = []
    for d in docs:
        # d may be Document or string
        if isinstance(d, Document):
            formatted.append(d.page_content)
        else:
            formatted.append(str(d))
    return "\n\n---\n\n".join(formatted)


def format_docs_as_context(docs):
    """RAG í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ì¢‹ì€ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ì¶œì²˜ ë©”íƒ€ë°ì´í„° í¬í•¨)"""
    if not docs:
        return ""
    parts = []
    for i, d in enumerate(docs, 1):
        if isinstance(d, Document):
            src = d.metadata.get("source", d.metadata.get("url", "unknown"))
            parts.append(f"[ë¬¸ì„œ {i}] (ì¶œì²˜: {src})\n{d.page_content}")
        else:
            parts.append(f"[ë¬¸ì„œ {i}]\n{str(d)}")
    return "\n\n---\n\n".join(parts)

def search_documents(queries, k_per_query=10):
    """vectorstoreì—ì„œ ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰ í›„ ì¤‘ë³µì œê±° â†’ (Document, similarity) ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    all_docs_with_scores = []
    seen_contents = set()
    for q in queries:
        try:
            docs_with_scores = vectorstore.similarity_search_with_score(q, k=k_per_query)
        except Exception as e:
            print("âš  vectorstore.similarity_search_with_score ì˜¤ë¥˜:", e)
            docs_with_scores = []
        for doc, distance in docs_with_scores:
            # ì•ˆì „í•˜ê²Œ page_content ë¹„êµë¡œ ì¤‘ë³µ ë°©ì§€
            content = getattr(doc, "page_content", None) or str(doc)
            if content in seen_contents:
                continue
            seen_contents.add(content)
            # chorma distance -> ìœ ì‚¬ë„(0-1) ê·¼ì‚¬ ë³€í™˜ (distanceê°€ 0ì´ë©´ ì™„ì „ ë™ì¼)
            try:
                similarity = max(0.0, 1.0 - (distance / 2.0))
            except Exception:
                similarity = 0.0
            all_docs_with_scores.append((doc, similarity))
    return all_docs_with_scores

def filter_by_similarity(docs_with_scores, threshold=0.3):
    return [(doc, sim) for doc, sim in docs_with_scores if sim >= threshold]

def check_relevance(question, docs_with_scores):
    """LLMì—ê²Œ ìƒìœ„ Nê°œ ë¬¸ì„œë¡œ ê´€ë ¨ì„± ë¬¼ì–´ë³´ê¸° -> True/False ë°˜í™˜"""
    # docs_with_scoresëŠ” (doc, sim)
    top_docs = docs_with_scores[:5]
    if not top_docs:
        return False
    docs_text = "\n\n---\n\n".join(
        f"[ë¬¸ì„œ {i+1}] (ì¶œì²˜: {getattr(doc.metadata,'get',lambda k, d=None: 'unknown')('source','unknown')})\n{getattr(doc,'page_content',str(doc))[:600]}"
        for i, (doc, _) in enumerate(top_docs)
    )
    try:
        res = relevance_chain.invoke({"question": question, "documents": docs_text})
        return "ê´€ë ¨ìˆìŒ" in res
    except Exception as e:
        print("âš  relevance_chain.invoke ì˜¤ë¥˜:", e)
        return False

def web_search(query: str, k=3):
    """Tavily API ê¸°ë°˜ ì›¹ê²€ìƒ‰"""
    try:
        retriever = TavilySearchAPIRetriever(k=k)
        results = retriever.invoke(query)  # ë³´í†µ Document ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” dict ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        # ì •ìƒí™”: Document ê°ì²´ë¡œ
        docs = []
        # ê²°ê³¼ê°€ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ìˆìŒ
        for r in results:
            if isinstance(r, Document):
                docs.append(r)
            elif isinstance(r, dict):
                text = r.get("content") or r.get("snippet") or r.get("title") or str(r)
                docs.append(Document(page_content=text, metadata={"source": "web", "url": r.get("url")}))
            else:
                # fallback string
                docs.append(Document(page_content=str(r), metadata={"source": "web"}))
        return docs
    except Exception as e:
        raise RuntimeError(f"Tavily ì›¹ê²€ìƒ‰ ì˜¤ë¥˜: {e}")

def format_web_results_for_prompt(results):
    """ì›¹ ê²°ê³¼(dict/list)ë¥¼ í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ì¢‹ì€ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    if not results:
        return ""
    items = []
    for i, r in enumerate(results, 1):
        title = getattr(r, "metadata", {}).get("title") if isinstance(r, Document) else (r.get("title") if isinstance(r, dict) else None)
        snippet = getattr(r, "page_content", None) if isinstance(r, Document) else (r.get("snippet") if isinstance(r, dict) else str(r))
        url = getattr(r, "metadata", {}).get("url") if isinstance(r, Document) else (r.get("url") if isinstance(r, dict) else None)
        items.append(f"â–  ì œëª©: {title or 'ì œëª© ì—†ìŒ'}\nìš”ì•½: {snippet}\në§í¬: {url or 'ì—†ìŒ'}")
    return "\n\n---\n\n".join(items)

# -----------------------
# RAG ì‘ë‹µ ìƒì„± í•¨ìˆ˜
# -----------------------
def rag_answer_from_docs(question: str, documents):
    """ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸(Document ë˜ëŠ” (doc,score) í˜¼í•©)ì„ ë°›ì•„ RAG ì‘ë‹µ ìƒì„±"""
    # í—ˆìš©ë˜ëŠ” ì…ë ¥ ë³€í˜•ì„ ì •ìƒí™”
    normalized_docs = []
    for item in documents:
        if isinstance(item, tuple) and len(item) >= 1:
            doc = item[0]
        else:
            doc = item
        if isinstance(doc, Document):
            normalized_docs.append(doc)
        else:
            normalized_docs.append(Document(page_content=str(doc), metadata={"source": "unknown"}))

    context = format_docs_as_context(normalized_docs)
    if not context.strip():
        print("âš  context ë¹„ì–´ìˆìŒ -> fallback LLMë¡œ ì´ë™")
        return fallback_chain.invoke({"question": question})

    prompt, pname = choose_prompt(question)
    print(f"[í”„ë¡¬í”„íŠ¸ ì‚¬ìš©] {pname} (ë¬¸ì„œ ê¸°ë°˜)")
    try:
        answer = (prompt | llm | StrOutputParser()).invoke({"context": context, "question": question})
        return answer
    except Exception as e:
        print("âš  rag_answer invoke ì˜¤ë¥˜:", e)
        return fallback_chain.invoke({"question": question})
    
# ========================================
# ë©”ì¸ RAG í•¨ìˆ˜
# ========================================
def multi_query_rag_with_qt(question: str, top_k=10, similarity_threshold=0.3):
    """
    ì „ì²´ íë¦„:
      1) ì¿¼ë¦¬ íŠ¸ëœìŠ¤í¼ (QT)
      2) ë©€í‹°ì¿¼ë¦¬ ìƒì„± (MQ)
      3) ë²¡í„°ê²€ìƒ‰ (ë©€í‹°ì¿¼ë¦¬)
      4) ìœ ì‚¬ë„ í•„í„°ë§
        - ë¬¸ì„œ ìˆìŒ -> LLM ê´€ë ¨ì„± ê²€ì¦
        - ë¬¸ì„œ ì—†ìŒ / ê´€ë ¨ ì—†ìŒ -> ì›¹ê²€ìƒ‰ ë˜ëŠ” Fallback (ë‹¨ì¼ ë¶„ê¸°)
    """
    
    # 1) Query Transform
    try:
        qt_query = qt_chain.invoke({"question": question})
    except Exception as e:
        print("âš  QT ì²´ì¸ ì˜¤ë¥˜:", e)
        qt_query = question 
    print(f"[QT] ë³€í™˜: {qt_query}")

    # 2) Multi Query
    try:
        mq_text = multi_query_chain.invoke({"question": qt_query})
        queries = [line.strip() for line in mq_text.splitlines() if line.strip()]
    except Exception as e:
        print("âš  MQ ì²´ì¸ ì˜¤ë¥˜:", e)
        queries = [qt_query]
    print(f"[ë©€í‹°ì¿¼ë¦¬] {len(queries)}ê°œ: {queries}")

    # 3) Vector search (ë©€í‹°ì¿¼ë¦¬)
    all_docs = search_documents(queries)
    print(f"[ê²€ìƒ‰] ì´ {len(all_docs)}ê°œ ë¬¸ì„œ í›„ë³´ í™•ë³´")

    # 4) ìœ ì‚¬ë„ í•„í„°ë§
    filtered_docs = filter_by_similarity(all_docs, similarity_threshold)
    print(f"[1ì°¨ í•„í„°ë§] ìœ ì‚¬ë„ >={similarity_threshold}: {len(filtered_docs)}ê°œ")

    # ----------------------------------------------------
    # ğŸ‘‡ ì£¼ìš” ë³€ê²½ ì‚¬í•­: ì¡°ê±´ ê²€ì‚¬ ë° ì›¹ ê²€ìƒ‰ í†µí•©
    # ----------------------------------------------------
    
    is_relevant = False
    
    if filtered_docs:
        # ë¬¸ì„œê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ LLMìœ¼ë¡œ ê´€ë ¨ì„± ê²€ì‚¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        print("[2ì°¨ í•„í„°ë§] LLM ê´€ë ¨ì„± ê²€ì¦ ì¤‘...")
        try:
            is_relevant = check_relevance(question, filtered_docs)
        except Exception as e:
            print("âš  ê´€ë ¨ì„± ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜:", e)
            is_relevant = False 

    # 5) ìµœì¢… ë¶„ê¸°: ë‚´ë¶€ RAG vs. ì›¹ ê²€ìƒ‰/Fallback
    if is_relevant:
        # âœ… ë‚´ë¶€ RAG ì‹¤í–‰: ë¬¸ì„œê°€ ìˆê³ , ê´€ë ¨ì„±ë„ ìˆìŒ
        print("âœ… ë‚´ë¶€ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ìˆìŒ â†’ ë‚´ë¶€ RAG ì‹¤í–‰")
        useful = filtered_docs[:top_k]
        return rag_answer_from_docs(question, useful)
    else:
        # âŒ ì›¹ ê²€ìƒ‰/Fallback ì‹¤í–‰: ë¬¸ì„œê°€ ì—†ê±°ë‚˜, ê´€ë ¨ì„±ì´ ì—†ìŒ
        # ì´ ë¶„ê¸°ì—ì„œ ì›¹ ê²€ìƒ‰ì´ ë‹¨ í•œ ë²ˆë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤.
        print("âŒ ë‚´ë¶€ ë¬¸ì„œ (ì—†ê±°ë‚˜/ë¬´ê´€) â†’ ì›¹ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜")
        
        try:
            # ì›¹ ê²€ìƒ‰ ì‹œë„
            web_docs = web_search(question)
        except Exception as e:
            print(f"âŒ ì›¹ê²€ìƒ‰ ì‹¤íŒ¨ (Tavily ì˜¤ë¥˜): {e}")
            # ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ìµœì¢… Fallback
            return fallback_chain.invoke({"question": question})

        if not web_docs:
            print("âŒ ì›¹ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ â†’ LLM ìì²´ì§€ì‹ìœ¼ë¡œ ì‘ë‹µ")
            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ì‹œ ìµœì¢… Fallback
            return fallback_chain.invoke({"question": question})
        
        # ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆì„ ì‹œ ì›¹ RAG ì‹¤í–‰
        return rag_answer_from_docs(question, web_docs)

# -----------------------
# ì‹¤í–‰ í…ŒìŠ¤íŠ¸
# -----------------------
if __name__ == "__main__":
    test_cases = [
        "ì„œìš¸ì—ì„œ AI ì±—ë´‡ ì°½ì—…ì„ í•˜ë ¤ê³  í•˜ëŠ”ë° ë°›ì„ ìˆ˜ ìˆëŠ” ì§€ì›ì‚¬ì—… ìˆë‚˜ìš”?",
        "ì„œìš¸ì— ìˆëŠ” ë™ë¬¼ë³‘ì› ì•Œë ¤ì£¼ì„¸ìš”",
        "ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜"
    ]

    for q in test_cases:
        print("\n" + "="*80)
        print("[ì§ˆë¬¸]", q)
        print("="*80)
        try:
            ans = multi_query_rag_with_qt(q)
            print("\n[ë‹µë³€]\n", ans)
        except Exception as e:
            print("ì „ì²´ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜:", e)
