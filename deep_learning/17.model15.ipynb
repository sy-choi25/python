{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e3a94f4",
   "metadata": {},
   "source": [
    "<span style=\"font-size:12px;\">\n",
    "\n",
    "▶ EfficentNet : 2019 Google Brain\n",
    "- 딥러닝 CNn 구조를 효율적으로 확장하는 방법을 제시한 모델\n",
    "- 기존 모델보다 파마메터 수를 줄이고 더 정확도를 높임\n",
    "- 기존 CNN\n",
    "    - 깊이 : ResNet (50 -> 101) 층을 더 쌓는다\n",
    "    - 너비 : WideResnet 각 층의 채널수를 놀린다\n",
    "    - 해상도 : 224 -> 331 큰 이미지를 사용\n",
    "    => 각각 따로 늘리면 성능 향상 대비 비용이 너무 크기 떄문에 균형 잡힌 확장 방법을 제시\n",
    "- 깊이 너비 해상도 --> 비율로 동시에 확장. 균형 잡히게 조금씩 다 키우자!\n",
    "- BaseLine MBConv => 적은 연산량으로 성능을 유지하기 위해 채널을 확장했다가 다시 줄이는 병목구조의 합셩곱 블록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c6a5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit     # 시그모이드 함수와 동일\n",
    "# ~10 - 10 까지의 0.2 간격\n",
    "x = np.arange(-10,10,0.2)\n",
    "\n",
    "# ReLU함수\n",
    "# x.clip(0) 0보다 작으면 0, 0보다 크면 x 자신으로 만듦\n",
    "plt.plot(x, x.clip(0), label = 'relu')\n",
    "\n",
    "# swich 함수\n",
    "plt.plot(x, x * expit(x), label='swich')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "060d888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from tqdm import tqdm   # 학습진행률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46048a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4,0.4,0.4),(0.2,0.2,0.2))\n",
    "])\n",
    "# 이미지 데이터 로드\n",
    "trainset = torchvision.datasets.CIFAR10(root = './', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root = './', train=False, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = 64)\n",
    "classs = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse','ship','truck')\n",
    "model = models.efficientnet_b0(weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbede1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eca9657c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/782 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 20/782 [14:30<9:12:28, 43.50s/it]\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x000001B52360BC10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 781, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m optimizer.zero_grad()\n\u001b[32m     12\u001b[39m inputs, labels = data[\u001b[32m0\u001b[39m].to(device),data[\u001b[32m1\u001b[39m].to(device)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     16\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torchvision\\models\\efficientnet.py:343\u001b[39m, in \u001b[36mEfficientNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torchvision\\models\\efficientnet.py:333\u001b[39m, in \u001b[36mEfficientNet._forward_impl\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.avgpool(x)\n\u001b[32m    336\u001b[39m     x = torch.flatten(x, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torchvision\\models\\efficientnet.py:164\u001b[39m, in \u001b[36mMBConv.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_res_connect:\n\u001b[32m    166\u001b[39m         result = \u001b[38;5;28mself\u001b[39m.stochastic_depth(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:432\u001b[39m, in \u001b[36mSiLU.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SAMSUNG\\anaconda3\\envs\\deep\\Lib\\site-packages\\torch\\nn\\functional.py:2379\u001b[39m, in \u001b[36msilu\u001b[39m\u001b[34m(input, inplace)\u001b[39m\n\u001b[32m   2377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace=inplace)\n\u001b[32m   2378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m-> \u001b[39m\u001b[32m2379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43msilu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2380\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch._C._nn.silu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "# 손실함수 옵티마이져\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 기존모델의 가중치 + 사용자의 데이터로 학습  -> fine turnning -> learing rage를 작게 가져오는 경향이 있음 (보통 1e-3인데 1e-4정도)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "for epoch in range(5):\n",
    "    batch_loss = 0\n",
    "    for i, data in enumerate(tqdm(trainloader)):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = data[0].to(device),data[1].to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'epoch : {epoch+1} loss : {batch_loss/len(trainloader)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
