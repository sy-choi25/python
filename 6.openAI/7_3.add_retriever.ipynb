{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c9bcc4",
   "metadata": {},
   "source": [
    "<span style=\"color: lightblue;\"> 전체 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb2f0cd",
   "metadata": {},
   "source": [
    "``` text\n",
    "+---------+       +-------+      +---------------+\n",
    "| START   | ---> |retriever| --> |   grade       |\n",
    "+---------+       +-------+      +--------+------+\n",
    "                                    |        |\n",
    "                                    |문서O   | 문서X\n",
    "                                    |        v\n",
    "                                    v      web_search\n",
    "                               generate\n",
    "                                    ↓\n",
    "                                   END\n",
    "                                   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d1849f",
   "metadata": {},
   "source": [
    "<span style=\"color: lightblue;\"> state 는 공용 저장소\n",
    " \n",
    "모든 노드가 같은 state 딕셔너리를 공유하면서 값을 바꾼다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ec5020",
   "metadata": {},
   "source": [
    "```text\n",
    "state  \n",
    " ├─ question  \n",
    " ├─ documents  \n",
    " ├─ doc_scores  \n",
    " ├─ search_type  \n",
    " └─ answer  \n",
    "\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a807ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from typing import List, Literal\n",
    "from typing_extensions import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain 관련 임포트\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "# LangGraph 관련 임포트\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# 환경설정\n",
    "load_dotenv()\n",
    "\n",
    "if not os.environ.get('OPENAI_API_KEY'):\n",
    "    raise ValueError('key check....')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a14217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs path : c:\\python_src\\6.openAI\n",
      "VectorDB 구축 완료 청크개수 : 21\n",
      " [retriever] 3개 문서 검색됨\n",
      "[grade] 3개 --> 1개 문서 유지\n",
      "\n",
      " 답변 :\n",
      " LangGraph의 핵심 개념은 다음과 같습니다:\n",
      "\n",
      "1. **State(상태)**: 에이전트의 현재 상태를 나타내는 데이터 구조로, 에이전트가 수행하는 작업이나 프로세스의 진행 상황을 기록합니다. 이 상태는 에이전트가 다음에 어떤 행동을 취할지를 결정하는 데 중요한 역할을 합니다.\n",
      "\n",
      "2. **Node(노드)**: 실제 작업을 수행하는 함수로, 특정 작업이나 기능을 실행하는 단위입니다. 각 노드는 특정한 기능을 가지고 있으며, 에이전트가 수행해야 할 작업을 정의합니다.\n",
      "\n",
      "3. **Edge(엣지)**: 노드 간의 제어 흐름을 정의하는 요소로, 한 노드에서 다른 노드로의 전환을 나타냅니다. 엣지는 작업의 순서를 결정하고, 노드 간의 관계를 형성합니다.\n",
      "\n",
      "4. **Conditional Edge**: 조건에 따라 다른 노드로 분기하는 엣지로, 특정 조건이 충족되면 다른 경로로 진행할 수 있게 합니다. 이를 통해 에이전트는 상황에 맞는 적절한 행동을 선택할 수 있습니다.\n",
      "\n",
      "이러한 개념들은 LangGraph의 구조와 동작 방식을 이해하는 데 필수적이며, 에이전트가 복잡한 작업을 효율적으로 수행할 수 있도록 돕습니다.\n",
      "\n",
      " 검색유형 :internal, 참조문서 : 1개\n",
      " [retriever] 3개 문서 검색됨\n",
      "[grade] 3개 --> 0개 문서 유지\n",
      "\n",
      " 답변 :\n",
      " RAG는 \"Retrieval-Augmented Generation\"의 약자로, 정보 검색과 생성 모델을 결합한 접근 방식을 의미합니다. 이 방법은 주어진 질문이나 요청에 대해 관련 정보를 검색한 후, 그 정보를 바탕으로 자연어로 응답을 생성하는 방식입니다. RAG는 특히 대규모 데이터베이스나 문서에서 필요한 정보를 효과적으로 찾아내고, 이를 활용하여 더 정확하고 풍부한 답변을 제공하는 데 유용합니다. 이 기술은 자연어 처리(NLP) 분야에서 많이 활용되고 있으며, 챗봇, 질문 응답 시스템 등 다양한 응용 프로그램에 적용될 수 있습니다.\n",
      "\n",
      " 검색유형 :web, 참조문서 : 0개\n",
      " [retriever] 3개 문서 검색됨\n",
      "[grade] 3개 --> 0개 문서 유지\n",
      "\n",
      " 답변 :\n",
      " 오늘 서울의 날씨는 맑고 기온은 약 20도 정도입니다. 바람은 약간 불고 있으며, 전반적으로 쾌적한 날씨입니다. 외출하기 좋은 날씨니 가벼운 옷차림으로 나가셔도 좋을 것 같습니다.\n",
      "\n",
      " 검색유형 :web, 참조문서 : 0개\n"
     ]
    }
   ],
   "source": [
    "def langgraph_rag():\n",
    "    '''VectorDB 기반 LangGraph RAG'''\n",
    "    # 상태 정의\n",
    "    class RAGState(TypedDict):      # from pydantic import BaseModel 으로 불러온 BaseModel은 강제성이 있음, TypeDict은 힌트만 줄 뿐 강제성은 없음\n",
    "        question:str\n",
    "        documents : List[Document]\n",
    "        doc_scores : List[float]    # 유사도 점수\n",
    "        search_type : str\n",
    "        answer : str\n",
    "\n",
    "    # 문서 로드\n",
    "    script_dir = os.getcwd()\n",
    "    docs_path = os.path.join(script_dir)\n",
    "    print(f'docs path : {docs_path}')\n",
    "\n",
    "    loader = DirectoryLoader(\n",
    "        docs_path,\n",
    "        glob = '**/*.txt',\n",
    "        loader_cls = TextLoader,\n",
    "        loader_kwargs={'encoding':'utf-8'},  # 한국어면 꼭 써줄 것\n",
    "    )\n",
    "    docs= loader.load()\n",
    "\n",
    "    # VectorDB 구축 -> 청킹\n",
    "    text_spliter =  RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50,separators= ['\\n\\n','\\n','.',' ',''])\n",
    "    splits = text_spliter.split_documents(docs)\n",
    "\n",
    "    vectorstores = Chroma.from_documents(\n",
    "        documents=splits,\n",
    "        embedding=OpenAIEmbeddings(model='text-embedding-3-small'),\n",
    "        collection_name='langgraph'\n",
    "    )\n",
    "    print(f'VectorDB 구축 완료 청크개수 : {len(splits)}')\n",
    "\n",
    "    # llm 초기화\n",
    "    llm = ChatOpenAI(model='gpt-4o-mini',temperature=0)\n",
    "\n",
    "    # 노드 함수들\n",
    "        # 리트리버 함수\n",
    "    def retrieve_node(state:RAGState)->dict:    # state:RAGState 이 의미는 state는 RAGState 형식이라는 뜻\n",
    "        '''검색 노드'''\n",
    "        quesiton = state['question']\n",
    "        docs_with_scores = vectorstores.similarity_search_with_score(quesiton, k = 3)\n",
    "        documents =  [ doc for doc,score in docs_with_scores]\n",
    "        scores =  [ 1-score for doc,score in docs_with_scores]\n",
    "\n",
    "        print(f' [retriever] {len(documents)}개 문서 검색됨')        \n",
    "        return {'documents': documents, 'doc_scores':scores, 'search_type':'internal'}   # state 업데이트\n",
    "\n",
    "    def grade_documents_node(state:RAGState)->dict:\n",
    "        '''문서평가 노드'''\n",
    "        threshold = 0.3 # -> 유사도 점수 최소 기준값\n",
    "        filtered_docs, filtered_scores = [],[]  # 유사도 최소 기준값 조건을 통과한 문서만 담을 빈 리스트\n",
    "        for doc, score in zip(state['documents'],state['doc_scores']): # state['documents'] (리트리버가 반환한 문서들)/ state['doc_scores'] (그 문서들의 유사도 점수)\n",
    "            if score >= threshold:  # score가 0.3 이상인 것들만 통과\n",
    "                filtered_docs.append(doc); filtered_scores.append(score) # 통과한 문서들을 더해준다     # ; 두 줄을 한줄로 합친것\n",
    "        print(f\"[grade] {len(state['documents'])}개 --> {len(filtered_docs)}개 문서 유지\")\n",
    "        return {'documents' : filtered_docs, 'doc_scores':filtered_scores}\n",
    "\n",
    "    def web_search_node(state:RAGState)->dict:\n",
    "        '''웹검색 노드(시뮬레이션)'''\n",
    "        web_result = Document(\n",
    "            page_content=f\"웹 검색 결과 : {state['question']}에 대한 최신 결과 입니다.\",\n",
    "            metadata = {'source':'web_search'}\n",
    "        )\n",
    "        return {'document':[web_result],'doc_scores':[0.8], 'search_type':'web'}\n",
    "\n",
    "    def generate_node(state:RAGState)->dict:\n",
    "        '''생성노드'''  \n",
    "        context = '\\n'.join([ doc.page_content for doc in state['documents']])\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            ('system','제공된 문맥을 바탕으로 한국어로 답변하세요'),\n",
    "            ('human', '문맥:\\n{context}\\n\\n질문:{question}\\n\\n답변:')\n",
    "        ])\n",
    "        chain = prompt | llm | StrOutputParser()\n",
    "        answer = chain.invoke({'context':context, 'question' : state['question'] })\n",
    "        return {'answer':answer}\n",
    "    \n",
    "    # 조건 함수\n",
    "    def decide_to_generate(state:RAGState)-> Literal['generate','web_search']:\n",
    "        '''조건부 분기 함수'''    \n",
    "        if state['documents'] and len(state['documents']) > 0:\n",
    "            return 'generate'\n",
    "        else:\n",
    "            return 'web_search'\n",
    "\n",
    "    # 그래프 구축(add_node  add_edge  add_conditional_edges)\n",
    "    graph = StateGraph(RAGState)\n",
    "    graph.add_node('retriever',retrieve_node)\n",
    "    graph.add_node('grade',grade_documents_node)\n",
    "    graph.add_node('web_search',web_search_node)\n",
    "    graph.add_node('generate',generate_node)\n",
    "\n",
    "    graph.add_edge(START, 'retriever')\n",
    "    graph.add_edge('retriever', 'grade')\n",
    "    graph.add_conditional_edges(\n",
    "        'grade',\n",
    "        decide_to_generate,\n",
    "        { 'generate':'generate', 'web_search': 'web_search'}\n",
    "    )\n",
    "    graph.add_edge('web_search', 'generate')    # 웹 검색을 바탕으로 최종 답변을 생성\n",
    "    graph.add_edge('generate', END)\n",
    "    # 그래프 컴파일\n",
    "\n",
    "    app = graph.compile()       # 노드와 엣지를 내부적으로 연결. 노드와 엣지 설정 후 꼭 써줘야 실행함\n",
    "    # 그래프 invoke(질문)\n",
    "    test_qeustion = [\n",
    "        'LangGraph의 핵심 개념을 설명해 주세요',\n",
    "        'RAG란 무엇인가요?',\n",
    "        '오늘 서울 날씨는 어떤가요?'  # 내부 문서에 없음\n",
    "    ]\n",
    "    # 각 질문에 대한 출력\n",
    "    for question in test_qeustion:        \n",
    "        result = app.invoke({\n",
    "            'question':question,\n",
    "            'documents' : [],\n",
    "            'doc_scores' : [],\n",
    "            'search_type' : \"\",\n",
    "            'answer' : \"\"\n",
    "        })\n",
    "\n",
    "        print(f'\\n 답변 :\\n {result['answer']}')\n",
    "        print(f'\\n 검색유형 :{result['search_type']}, 참조문서 : {len(result['documents'])}개')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    langgraph_rag()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
