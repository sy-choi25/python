{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b668753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\samsung\\miniconda3\\envs\\llm_env\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\samsung\\miniconda3\\envs\\llm_env\\lib\\site-packages (from faiss-cpu) (2.2.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\samsung\\miniconda3\\envs\\llm_env\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389ed97d",
   "metadata": {},
   "source": [
    "<span style=\"font-size:12px;\">\n",
    "\n",
    "FAISS\n",
    "- FAISS에서 대규모 벡터 검색을 빠르고 효율적으로 하려고 만든 세 가지 핵심 접근 방식: IVF, PQ, HNSW\n",
    "\n",
    "---\n",
    "- <span style=\"color: Gold\"> IVF (Inverted File Index) </span>\n",
    "    - 개념: 벡터 공간을 여러 **클러스터(그룹)**로 나눔\n",
    "    - 목적: 쿼리와 관련 없는 벡터는 탐색하지 않아 속도를 높임\n",
    "    - 장점: 대규모 벡터에서 속도 빠름\n",
    "    - 단점: 일부 정확도 손실 가능\n",
    "    - 동작:\n",
    "        - K-means로 클러스터(nlist) 생성\n",
    "        - 각 벡터를 가장 가까운 클러스터에 할당\n",
    "        - 검색 시 쿼리와 가까운 nprobe 클러스터만 탐색\n",
    "\n",
    "- <span style=\"color: Gold\"> PQ (Product Quantization)</span>\n",
    "    - 개념: 고차원 벡터를 여러 서브벡터로 나눈 후, 각 서브벡터를 대표 값(클러스터)으로 근사\n",
    "    - 목적: 메모리 절감 + 빠른 근사 거리 계산\n",
    "    - 장점: 메모리 절감, 검색 속도 빠름\n",
    "    - 단점: 근사로 인한 정확도 손실\n",
    "    - 동작:\n",
    "        - 벡터를 서브벡터로 분할 (예: 768차원 → 8개 × 96차원)\n",
    "        - 각 서브벡터를 코드북에 가장 가까운 값으로 치환\n",
    "        - 검색 시 코드만으로 근사 거리 계산\n",
    "\n",
    "- <span style=\"color: Gold\"> HNSW (Hierarchical Navigable Small World)</span>\n",
    "    - 개념: 다층 그래프 구조에서 벡터를 연결해 근사 최근접 탐색\n",
    "    - 목적: 빠른 검색 + 높은 정확도\n",
    "    - 장점: 속도 매우 빠름, 정확도 높음\n",
    "    - 단점: 메모리 중간 수준, 그래프 구축 필요\n",
    "    - 동작:\n",
    "        - 상위 레이어 → 장거리 점프 (빠른 후보 탐색)\n",
    "        - 하위 레이어 → 지역 탐색 (정밀도)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fffef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS 사용\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa6497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "np.random.seed(42)\n",
    "d= 128 # 벡터수\n",
    "n = 10000 # 데이터 수\n",
    "xb = np.random.randn(n,d).astype('float32') # 데이터베이스 / 랜덤 데이터베이스 생성\n",
    "xq = np.random.randn(5,d).astype('float32') # 쿼리 / 랜덤 질문 쿼리 생성\n",
    "\n",
    "# 정확한 검색\n",
    "index_flat = faiss.IndexFlatL2(d) # 모든 DB 벡터와 L2 거리 계산\n",
    "index_flat.add(xb)                # FAISS 인덱스에 벡터 추가\n",
    "\n",
    "# 상위 4개 검색\n",
    "k=4\n",
    "D,I = index_flat.search(xq,k)\n",
    "# k → 상위 k개 결과 검색\n",
    "# D → 쿼리별 상위 k개 벡터와의 L2 거리\n",
    "# I → 쿼리별 상위 k개 벡터 DB 인덱스 번호\n",
    "# I[0] → 첫 번째 쿼리 벡터와 가장 가까운 DB 벡터 인덱스\n",
    "print(f'Flat 인덱스 결과')\n",
    "print(f'거리 : {D}')  # 쿼리와 DB 벡터 사이의 L2 거리 (작을수록 가까움)\n",
    "print(f'인덱스 : {I}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1377c9e",
   "metadata": {},
   "source": [
    "IFV 원리: 벡터 공간을 여러 클러스터로 분할하고, 검색 시 관련 클러스터만 탐색\n",
    "\n",
    "- 나누는 이유 : ㅁ노든 벡터와 비교하면 느리기 때문에 클러스터 단위로 나누면 쿼리와 \n",
    "관련된 벡터만 탐색 가능하여 속도가 대폭 개선된다 \n",
    "\n",
    "2️⃣ 구조와 동작\n",
    "\n",
    "학습 단계\n",
    "\n",
    "K-means로 벡터 공간을 nlist 개의 클러스터로 나눔\n",
    "\n",
    "각 클러스터 중심을 저장\n",
    "\n",
    "벡터 추가 단계\n",
    "\n",
    "각 벡터를 가장 가까운 클러스터에 할당\n",
    "\n",
    "검색 단계\n",
    "\n",
    "쿼리 벡터와 가장 가까운 nprobe 개 클러스터만 탐색\n",
    "\n",
    "클러스터 내부는 Flat(L2) 또는 PQ로 거리 계산\n",
    "\n",
    "=> 문장 벡터들 중에서 연관성 있는 문장 벡터끼리 클러스터로 묶어 관련있는 것만 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bb0968",
   "metadata": {},
   "outputs": [],
   "source": [
    "d= 128 # 벡터수\n",
    "n = 10000 # 데이터 수\n",
    "xb = np.random.randn(n,d).astype('float32')# 데이터베이스\n",
    "# IVF 인덱스 생성   # IVF (Inverted File Index): FAISS에서 사용하는 근사 검색(ANN) 최적화 기법. 벡터를 여러 **클러스터(그룹)**로 나누고, 검색할 때 일부 클러스터만 탐색하는 방식\n",
    "# 클러스터 단위로 나누면 쿼리와 관련된 벡터만 탐색이 가능해 속도가 대폭 개선된다\n",
    "nlist = 100 # 클러스터\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index = faiss.IndexIVFFlat(quantizer,d,nlist)\n",
    "# 학습(클러스터링)\n",
    "index.train(xb)\n",
    "# 데이터 추가\n",
    "index.add(xb)\n",
    "# 검색(nprobe 조절)\n",
    "index.nprobe = 10 # 클러스터 수\n",
    "D,I = index.search(xq, k=5)\n",
    "print(f'IVF 인덱스 결과')\n",
    "print(f'거리 : {D}') \n",
    "print(f'인덱스 : {I}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72805aa7",
   "metadata": {},
   "source": [
    "- PQ (Product Quantization)\n",
    "고차원 벡터를 여러 서브벡터로 나누고, 각 서브벡터를 양자화(quantize)하여 압축하는 기법\n",
    "\n",
    "벡터는 원래 고차원인데 PQ에서는 이 벡터를 여러 작은 조작으로 나눈다. 차원이 낮은 단위로나누면 각 부분별로 근사화(압축)이 가능\n",
    "\n",
    "- 서브벡터 : 원래 벡터가 768차원이라면 \n",
    "서브벡터로 분할해서 이런식으로 \n",
    "\n",
    "Subvector1 = [v1, ..., v96]\n",
    "Subvector2 = [v97, ..., v192]\n",
    "...\n",
    "Subvector8 = [v673, ..., v768]\n",
    "\n",
    "- 양자화 : 실제 벡터 값을 근사값으로 바꾸는 과정. 각 서브벡터를 가장 가까운 **코드북 중심(대표 값)**으로 바꿔 저장\n",
    "\n",
    "서브벡터 분할 -> 서브벡터들 → 코드북학습(K-means) → centroid 집합 → 코드북 생성 -> 양자화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80e7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 128 # 벡터수\n",
    "n = 10000 # 데이터 수\n",
    "xb = np.random.randn(n,d).astype('float32')  # 데이터베이스\n",
    "\n",
    "# IVF + PQ 인덱스\n",
    "nlist = 100 # 클러스터 수\n",
    "m = 8 # 서브벡터 수( d가 m으로 나눠떨어져야 함)\n",
    "nbits = 8  # 각 서브벡터당 비트 수( 2^8) = 256 클러스터\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index = faiss.IndexIVFPQ(quantizer,d,nlist,m,nbits)\n",
    "# 학습\n",
    "index.train(xb)\n",
    "#추가\n",
    "index.add(xb)\n",
    "#검색\n",
    "index.nprobe = 10\n",
    "D,I =  index.search(xq, k=2)\n",
    "# 메모리 비교\n",
    "flat_memory = n*d*4\n",
    "pq_memory = n*m  # 각 벡터당 m바이트\n",
    "print(f'Flat 메모리 : {flat_memory / 1e6:.2f}MB')\n",
    "print(f'PQ 메모리 : {pq_memory / 1e6:.2f}MB')\n",
    "print(f'압축률 : {flat_memory / pq_memory:.0f}MB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dbd4df",
   "metadata": {},
   "source": [
    "HNSW (Hierarchical Navigable Small World)\n",
    "- FAISS에서 사용하는 근사 최근접 이웃 검색(ANN) 기법\n",
    "\n",
    "다층 그래프 구조를 이용해 벡터 간 유사도를 빠르게 탐색\n",
    "\n",
    "1️⃣ 구조\n",
    "\n",
    "여러 **레이어(layer)**로 구성된 그래프\n",
    "\n",
    "각 레이어에서 노드(벡터)끼리 연결되어 있음\n",
    "상위 레이어 → 멀리 있는 후보 벡터로 빠르게 이동\n",
    "\n",
    "하위 레이어 → 근처 벡터를 정밀 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3ad6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = 128 # 벡터수\n",
    "n = 10000 # 데이터 수\n",
    "xb = np.random.randn(n,d).astype('float32')  # 데이터베이스\n",
    "# HNSW 인덱스\n",
    "M=32 # 각 노드의 연결 수\n",
    "index = faiss.IndexHNSWFlat(d,M)\n",
    "# 인덱스 구축시 탐색 깊이\n",
    "index.hnsw.efConstruction = 40\n",
    "# 데이터 추가(학습불필요)\n",
    "index.add(xb)\n",
    "# 검색시 탐색 깊이\n",
    "index.hnsw.efSearch = 16\n",
    "D,I = index.search(xq, k=5)\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def benchmark_index(index, xb, xq, name):\n",
    "    \"\"\"인덱스 성능 벤치마크\"\"\"\n",
    "    # 추가 시간\n",
    "    start = time.time()\n",
    "    if hasattr(index, 'train'):\n",
    "        index.train(xb)\n",
    "    index.add(xb)\n",
    "    add_time = time.time() - start\n",
    "\n",
    "    # 검색 시간\n",
    "    start = time.time()\n",
    "    for _ in range(10):\n",
    "        index.search(xq, k=10)\n",
    "    search_time = (time.time() - start) / 10\n",
    "\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  추가 시간: {add_time:.3f}s\")\n",
    "    print(f\"  검색 시간: {search_time*1000:.2f}ms\")\n",
    "\n",
    "# 데이터 준비\n",
    "d, n = 128, 100000\n",
    "xb = np.random.randn(n, d).astype('float32')\n",
    "xq = np.random.randn(100, d).astype('float32')\n",
    "\n",
    "# Flat\n",
    "benchmark_index(faiss.IndexFlatL2(d), xb.copy(), xq, \"Flat\")\n",
    "\n",
    "# IVF\n",
    "nlist = 100\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index_ivf = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
    "benchmark_index(index_ivf, xb.copy(), xq, \"IVF\")\n",
    "\n",
    "# HNSW\n",
    "benchmark_index(faiss.IndexHNSWFlat(d, 32), xb.copy(), xq, \"HNSW\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
