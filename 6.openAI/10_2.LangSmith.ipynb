{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca7a435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "데이터셋 생성: qa_eval_dataset_20251204_141017\n",
      "    3개 예제 추가 완료\n",
      "데이터셋 생성 내용 확인\n",
      "  1  AI란?\n",
      "  2  1+1은?\n",
      "  3  Python이란 무엇인가요?\n",
      "View the evaluation results for experiment: 'formal-pen-22' at:\n",
      "https://smith.langchain.com/o/d80866a7-d58d-4d7c-a339-dbca1ad17033/datasets/57a009a5-4a42-42a1-b8d3-30108d7cdbca/compare?selectedSessions=d43d556b-ac45-483e-9401-1846ed5c8093\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:07,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "평가 결과 요약\n",
      "<ExperimentResults formal-pen-22>\n",
      " 데이터셋 삭제완료\n"
     ]
    }
   ],
   "source": [
    "# 이론부분의 sample 코드에 대한 완전히 구현한 코드\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import Any,Dict,List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# langsmith\n",
    "from langsmith import Client\n",
    "from langsmith.run_helpers import traceable\n",
    "\n",
    "# 환경설정\n",
    "load_dotenv()\n",
    "def check_environment():\n",
    "    '''환경변수 확인'''\n",
    "    missing_keys = []\n",
    "    if not os.getenv('OPENAI_API_KEY'):\n",
    "        missing_keys.append('OPENAI_API_KEY')\n",
    "    if not os.getenv('LANGCHAIN_API_KEY'):\n",
    "        missing_keys.append('LANGCHAIN_API_KEY')\n",
    "    if missing_keys:\n",
    "        print('필요한 API키가 없습니다.')\n",
    "        for key in missing_keys:\n",
    "            print(f' --------- {key}')\n",
    "        raise ValueError('필수 키 누락')\n",
    "    \n",
    "    # langsmith 추적 활성화\n",
    "    os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "    os.environ['LANGCHAIN_PROJECT'] = 'llm_rag_example'\n",
    "    print('환경설정 완료!')\n",
    "\n",
    "\n",
    "# langsmith  자동추적\n",
    "def auto_tracing():\n",
    "    '''langsmith 기본 사용법'''\n",
    "    llm = ChatOpenAI(model='gpt-4o-mini',temperature=0)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        ('system','당신은 친절한 ai 에이전트입니다. 사용자의 요구사항에 맞게 한글로 설명해주세요'),\n",
    "        ('human', '간단히 설명해주세요: {topic}')\n",
    "    ])\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    topics = ['Python','AI']\n",
    "    for topic in topics:\n",
    "        response = chain.invoke({'topic':topic})\n",
    "        print(f'   {topic} : {response[:50]}...')\n",
    "    print('자동추적 완료')\n",
    "\n",
    "def traceable_decorator():\n",
    "    '''커스텀함수에 @traceable 데코레이터를 사용해서 추적'''\n",
    "    llm = ChatOpenAI(model = 'gpt-4o-mini',temperature=0)\n",
    "\n",
    "    @traceable(name='custom_qa_function')\n",
    "    def answer_question(question:str) -> str:\n",
    "        '''질문에 답변하는 함수(langsmith에서 추적됨)'''\n",
    "        prompt = f'질문에 간단히 답해주세요 : {question}'\n",
    "        response = llm.invoke(prompt)\n",
    "        return response.content\n",
    "    @traceable(name=\"multi_step_analysis\")\n",
    "    def analyze_topic(topic:str)->Dict[str,str]:\n",
    "        '''여러 단계로 주제를 분석(중첩 추적)'''\n",
    "        # 단계 1: 정의\n",
    "        definition = answer_question(f'{topic}이란 무엇인가요?')\n",
    "        # 단계 2 : 장점\n",
    "        advantage = answer_question(f'{topic}의 장점은?')\n",
    "\n",
    "        return {\n",
    "            'topic':topic,\n",
    "            'definition' : definition[:100],\n",
    "            'advantage' : advantage[:100],\n",
    "        }\n",
    "    print('\\n@traceable 테스트')\n",
    "    result = analyze_topic('LangChain')\n",
    "    print(f\"    주제 : {result['topic']}\")\n",
    "    print(f\"    정의 : {result['definition']}\")\n",
    "    print(f\"    강점 : {result['advantage']}\")\n",
    "    print('\\n @traceable 데코레이터 완료!')\n",
    "\n",
    "\n",
    "\n",
    "# 메타데이터와 태그 추가    \n",
    "def metadata_tag():\n",
    "    '''추적에 메타데이터와 태그를 추가해서 필터링/분석에 활용'''\n",
    "    from langchain_core.runnables import RunnableConfig\n",
    "    llm = ChatOpenAI(model='gpt-4o-mini',temperature=0)\n",
    "    prompt = ChatPromptTemplate.from_template('{question}')\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    # 메타데이터와 태그 설정\n",
    "    config = RunnableConfig(\n",
    "        metadata = {\n",
    "            'user_id' : 'user_123',\n",
    "            'session_id' : 'sees_456',\n",
    "            'environment' : 'development',\n",
    "            'version':\"1.0.0\"\n",
    "        },\n",
    "        tags = ['example','qa','test']\n",
    "    )\n",
    "    print('\\n메타데이터 / 태그  테스트')\n",
    "    response = chain.invoke(\n",
    "        {'question':'RAG란 무엇인가요?'},\n",
    "        config = config\n",
    "    )\n",
    "    print('\\n메타데이터와 태그 추가 완료')\n",
    "\n",
    "\n",
    "# langSmith Client 직접 사용\n",
    "def langsmith_client():\n",
    "    '''LangSmith client를 직접사용해서 데이터를 조회'''\n",
    "    client = Client()\n",
    "    print('\\n프로젝트 목록 조회')\n",
    "    try:\n",
    "        projects = client.list_projects(limit=5)\n",
    "        if projects:\n",
    "            for project in projects:\n",
    "                print(f'    - {project.name}')\n",
    "    except Exception as e:\n",
    "        print(f'프로젝트 조회중 오류 발생 : {e}')\n",
    "    print('\\n최근 실행기록')\n",
    "    try:\n",
    "        project_name = os.getenv('LANGCHAIN_PROJECT','default')\n",
    "        runs = list(client.list_runs(\n",
    "            project_name=project_name,\n",
    "            limit=5\n",
    "        ))\n",
    "        if runs:\n",
    "            for run in runs:\n",
    "                status = 'success' if run.status == 'success' else 'faile'\n",
    "                duration = run.end_time - run.start_time   if run.start_time and run.end_time else 'N/A'\n",
    "                print(f'    {status} {run.name}  |  {duration}')\n",
    "    except Exception as e:\n",
    "        print(f'최근 실행기록 조회중 오류 발생 : {e}')\n",
    "    print('\\n langSmith Client 사용 완료')\n",
    "\n",
    "def dataset_evaluation():\n",
    "    '''langSmith에서 평가용 데이터셋을 생성하고 모델을 평가'''\n",
    "    client = Client()\n",
    "    # 데이터셋이름 생성(고유하게)\n",
    "    dataset_name = f\"qa_eval_dataset_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    print(f'\\n데이터셋 생성: {dataset_name}')\n",
    "\n",
    "    try:\n",
    "        dataset = client.create_dataset(\n",
    "            dataset_name=dataset_name,\n",
    "            description='QA 시스템 평가용 데이터셋'\n",
    "        )\n",
    "        # 평가용 예제\n",
    "        examples = [\n",
    "            {\n",
    "                \"inputs\": {\"question\": \"Python이란 무엇인가요?\"},\n",
    "                \"outputs\": {\"answer\": \"Python은 프로그래밍 언어입니다.\"}\n",
    "            },\n",
    "            {\n",
    "                \"inputs\": {\"question\": \"1+1은?\"},\n",
    "                \"outputs\": {\"answer\": \"2입니다.\"}\n",
    "            },\n",
    "            {\n",
    "                \"inputs\": {\"question\": \"AI란?\"},\n",
    "                \"outputs\": {\"answer\": \"인공지능입니다.\"}\n",
    "            }\n",
    "        ]\n",
    "        for ex in examples:\n",
    "            client.create_example(\n",
    "                inputs=ex['inputs'],\n",
    "                outputs=ex['outputs'],\n",
    "                dataset_id=dataset.id\n",
    "            )\n",
    "        print(f'    {len(examples)}개 예제 추가 완료')\n",
    "        # 데이터셋 생성 내용 확인\n",
    "        print('데이터셋 생성 내용 확인')\n",
    "        saved_examples = client.list_examples(dataset_id=dataset.id)\n",
    "        for i, ex in enumerate(saved_examples,1):\n",
    "            question = ex.inputs.get('question', 'N/A')\n",
    "            print(f'  {i}  {question}')\n",
    "        \n",
    "        \n",
    "         # 테스트 로직\n",
    "        from langsmith.evaluation import evaluate\n",
    "        client = Client()\n",
    "        # 평가모델 정의\n",
    "        llm = ChatOpenAI(model='gpt-4o-mini',temperature=0)\n",
    "        #평가 함수 실행\n",
    "        def predict(inputs:str)->Dict[str,str]:\n",
    "            q = inputs['question']\n",
    "            result = llm.invoke(f'{q} 간단히 답해줘')\n",
    "            return {'answer':result.content}\n",
    "        def simple_correctness(run, example):\n",
    "            \"\"\"run.outputs 로 모델 답변을 가져오는 방식\"\"\"\n",
    "\n",
    "            gold = example.outputs[\"answer\"]\n",
    "            pred = run.outputs[\"answer\"]\n",
    "\n",
    "            score = 1.0 if gold in pred else 0.0\n",
    "\n",
    "            return {\n",
    "                \"key\": \"correctness\",\n",
    "                \"score\": score,\n",
    "                \"comment\": f\"gold={gold} | pred={pred}\"\n",
    "            }\n",
    "        # 평가실행\n",
    "        results = evaluate(\n",
    "            predict,\n",
    "            data=dataset_name,            \n",
    "            evaluators=[simple_correctness]\n",
    "        )\n",
    "\n",
    "        print('\\n평가 결과 요약')\n",
    "        print(results)\n",
    "\n",
    "\n",
    "\n",
    "        # 정리 (테스트 후 삭제)\n",
    "        client.delete_dataset(dataset_id=dataset.id)\n",
    "        print(' 데이터셋 삭제완료')\n",
    "    except Exception as e:\n",
    "        print(f' 평가용 데이터셋 오류발생 : {e}')\n",
    "\n",
    "\n",
    "\n",
    "if __name__ =='__main__':\n",
    "    # check_environment()  #  환경체크\n",
    "    # auto_tracing() # 자동 추적\n",
    "    # traceable_decorator() # 커스텀 함수 추적\n",
    "    # metadata_tag() # 메타데이터 와 태그 추가\n",
    "    # langsmith_client()  # 데이터조회  client 사용\n",
    "    dataset_evaluation()  # 평가용 데이터셋 생성 및 확인 그리고 삭제\n",
    "    \n",
    "    \n",
    "    # @traceable(name=\"create_traking\")\n",
    "    # def add(a, b):\n",
    "    #     return a + b\n",
    "\n",
    "    # add(1, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
