{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcb8328a",
   "metadata": {},
   "source": [
    "LLM 에이전트 : LLM이 외부 도구를 활용해서 복잡한 테스크를 수행하는 시스템\n",
    "\n",
    "- 작동흐름: 사용자 요청 -> LLM(추론) -> 도구선택 -> 도구 실행 -> 결과 해석 -> 응답\n",
    "\n",
    "- 에이전트 대화 패턴\n",
    "user <-> Assistant\n",
    "사용자가 요청 -> 어시스턴스 응답 -> 사용자 피드백 반영\n",
    "\n",
    "- 각 에이전트가 전문 영역을 담당\n",
    "Manager -> Agent1 -> Agent2 -> Agent3 -> Manager\n",
    "→ Manager가 전체 작업 조율, Agent는 세부 작업 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5539fb0",
   "metadata": {},
   "source": [
    "AutoGen 프레임워크 : LLM을 기반으로 한 다중 에이전트 시스템을 쉽게 만들 수 있게 해주는 오픈소스 프레임워크\n",
    "\n",
    "- 핵심 기능\n",
    "    - 에이전트 간 협업\n",
    "    - Agent들이 대화를 통해 역할 분담 및 협업 수행\n",
    "    - LLM 지시 기반으로 코드 작성 + 실행 가능\n",
    "- 에이전트 종류\n",
    "    - AssistantAgent 지시에 따라서 작업수행\n",
    "    - UserProxyAgent 사용자 역할, 코드 실행\n",
    "    - GroupChatManager : 여러 에이전트 조율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c817d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0500c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# api 설정\n",
    "config_list = [\n",
    "    {\n",
    "        'model' : 'gpt-4o-mini',\n",
    "        'api_key': os.environ['OPENAI_API_KEY']\n",
    "    }\n",
    "]\n",
    "llm_config = {\n",
    "    'config_list' : config_list,\n",
    "    'temperature' : 0\n",
    "}\n",
    "# 어시스턴스 에이전트 생성\n",
    "import autogen\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name = 'Assistant',\n",
    "    llm_config = llm_config,\n",
    "    system_message = 'You are a helpful assistant.'\n",
    ")\n",
    "# user proxy 에이전트\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "  name = 'User_proxy',\n",
    "  human_input_mode = 'ALWAYS', # 자동실행\n",
    "  code_execution_config={\n",
    "      'work_dir' : 'coding',\n",
    "      'use_docker' : False\n",
    "  })\n",
    "# 대화\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message = '파이썬으로 팩토리얼 함수 작성해줘',\n",
    "    single_round = True) # 단일 라운드만 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1cc61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 실행 에이전트\n",
    "import autogen\n",
    "# 종료조건 설정\n",
    "def is_termination_msg(msg):\n",
    "  content = msg.get('content',\"\")\n",
    "  return content and content.strip().endswith('TERMINATE')\n",
    "\n",
    "# 어시스턴스 에이전트 생성\n",
    "import autogen\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name = 'Assistant',\n",
    "    llm_config = llm_config,\n",
    "    system_message = 'You are a helpful assistant.'\n",
    ")\n",
    "# user proxy 에이전트\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "  name = 'User_proxy',\n",
    "  is_termination_msg = is_termination_msg,\n",
    "  human_input_mode = 'NEVER',\n",
    "\n",
    "  code_execution_config={\n",
    "      'work_dir' : 'workspace',\n",
    "      'use_docker' : False\n",
    "  })\n",
    "\n",
    "# 대화\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message = '삼성전쟈의 최근 3개월치 주식 데이터를 가져와서 분석하고 시각화 해줘',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
