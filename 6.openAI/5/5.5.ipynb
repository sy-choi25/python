{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec274fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain 프롬프트 템플릿\n",
    "# LCEL 사용법\n",
    "# RAG 체인 구성 및 실행\n",
    "# 답변 품질 개선 전략\n",
    "\n",
    "# 파이프라인\n",
    "# [질문] -> [리트리버] -> [관련문서 검색] -> [프롬프트 제작] -> [LLM] -> [답변] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc385122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 경고 메세지 삭제\n",
    "warnings.filterwarnings('ignore')\n",
    "load_dotenv()\n",
    "\n",
    "# openapi key 확인\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key :\n",
    "    raise ValueError('.env 확인.. 키 없음')\n",
    "\n",
    "# 필수 라이브러리 로드\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09f3d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorDB 로드\n",
    "# 임베딩 모델 초기화\n",
    "embedding_model = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
    "# 이전 단계에서 저장한 vectordb 로드\n",
    "persist_dir = './chroma_db_rag2'\n",
    "config_file = 'vectordb_config.pkl'\n",
    "if os.path.exists(persist_dir):\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory = persist_dir,\n",
    "        collection_name = 'persistent_rag',\n",
    "        embedding_function = embedding_model\n",
    "    )\n",
    "else:\n",
    "    raise ValueError('이전단계 chroma_db_reg2 디렉터리 생성 필요')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b288cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리트리버 생성\n",
    "retriever =  vectorstore.as_retriever(search_kwargs={'k':3})\n",
    "\n",
    "# LLM 모델 생성\n",
    "llm = ChatOpenAI(\n",
    "    model = 'gpt-4o-mini',\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# 프롬프트 템플릿\n",
    "# 기본 RAG 프롬프트\n",
    "basic_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"당신은 제공된 문맥(Context)을 바탕으로 질문에 답변하는 AI 어시스턴트입니다.\n",
    "\n",
    "규칙:\n",
    "1. 제공된 문맥 내의 정보만을 사용하여 답변하세요.\n",
    "2. 문맥에 없는 정보는 \"제공된 문서에서 해당 정보를 찾을 수 없습니다.\"라고 답하세요.\n",
    "3. 답변은 한국어로 명확하고 간결하게 작성하세요.\n",
    "4. 가능하면 구조화된 형태(목록, 번호 등)로 답변하세요.\"\"\"),\n",
    "    (\"human\", \"\"\"문맥(Context):\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\"\"\")\n",
    "])\n",
    "\n",
    "# 상세 RAG 프롬프트\n",
    "detailed_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"당신은 전문적인 지식 기반 Q&A 시스템입니다.\n",
    "\n",
    "## 역할\n",
    "제공된 문맥을 분석하여 사용자의 질문에 정확하게 답변합니다.\n",
    "\n",
    "## 답변 규칙\n",
    "1. **출처 기반**: 반드시 제공된 문맥의 정보만 사용합니다.\n",
    "2. **정확성**: 문맥에 없는 내용은 추측하지 않습니다.\n",
    "3. **명확성**: 답변은 이해하기 쉽게 구조화합니다.\n",
    "4. **언어**: 한국어로 답변합니다.\n",
    "\n",
    "## 답변 불가 시\n",
    "문맥에서 정보를 찾을 수 없으면:\n",
    "\"제공된 문서에서 해당 정보를 찾을 수 없습니다. 다른 질문을 해주세요.\"\n",
    "라고 답변합니다.\"\"\"),\n",
    "    (\"human\", \"\"\"## 참조 문맥\n",
    "{context}\n",
    "\n",
    "## 질문\n",
    "{question}\n",
    "\n",
    "## 답변\"\"\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14f1c8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색된 문서 포멧팅 예시\n",
      "문서 1: rag_concept.txt\n",
      "RAG의 핵심 구성요소: Retriever(검색기), Generator(생성기), VectorStore(벡터저장소)\n",
      "\n",
      "---\n",
      "\n",
      "문서 2: rag_concept.txt\n",
      "RAG의 핵심 구성요소: Retriever(검색기), Generator(생성기), VectorStore(벡터저장소)\n",
      "기본 RAG 체인 구성 완료\n",
      "출처 포함 RAG 체인 구성 완료\n"
     ]
    }
   ],
   "source": [
    "# 문서 포메터 작성  : \n",
    "def format_docs(docs):\n",
    "    '''검색된 문서들을 하나의 문자열로 포맷팅'''\n",
    "    return '\\n\\n---\\n\\n'.join([ doc.page_content for doc in docs])\n",
    "\n",
    "def format_docs_with_source(docs):\n",
    "    '''출저 정보를 포함하여 문서 포멧팅'''\n",
    "    formatted = []\n",
    "    for i ,doc in enumerate(docs, 1):\n",
    "        source = doc.metadata.get('source','unknown')\n",
    "        formatted.append(f'문서 {i}: {source}\\n{doc.page_content}')\n",
    "    return '\\n\\n---\\n\\n'.join(formatted)\n",
    "\n",
    "# 테스트\n",
    "test_docs = retriever.invoke('RAG란 무엇인가요?')\n",
    "print('검색된 문서 포멧팅 예시')\n",
    "print(format_docs_with_source(test_docs[:2]))\n",
    "\n",
    "# RAG 체인 구성\n",
    "# 기본 RAG 체인(LCEL 사용)\n",
    "rag_chain = (\n",
    "    {'context': retriever | format_docs, 'question':RunnablePassthrough()}\n",
    "    | basic_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print('기본 RAG 체인 구성 완료')\n",
    "\n",
    "# 출처 포함 RAG 체인\n",
    "rag_chain_with_source =  (\n",
    "    {'context': retriever | format_docs_with_source, 'question':RunnablePassthrough()}\n",
    "    | basic_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print('출처 포함 RAG 체인 구성 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14815c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG 체인 테스트\n",
      "테스트 질문1 : RAG란 무엇이고 어떤 장점이 있나요?\n",
      "답변 : 제공된 문서에서 해당 정보를 찾을 수 없습니다.\n",
      "참조문서 : ['rag_concept.txt', 'rag_concept.txt', 'rag_concept.txt']\n",
      "소요된 시간 : 1.1757075786590576\n",
      "테스트 질문2 : LangChain의 주요 구성 요소를 설명해주세요.\n",
      "답변 : LangChain의 주요 구성 요소는 다음과 같습니다:\n",
      "\n",
      "1. **Models**: 다양한 LLM 제공자(OpenAI, Anthropic, Google 등)와 통합되어 있습니다.\n",
      "2. **Prompts**: 프롬프트 템플릿을 관리하고 최적화하는 기능을 제공합니다.\n",
      "3. **Chains**: 여러 구성 요소를 연결하는 파이프라인 역할을 합니다.\n",
      "4. **Memory**: 대화 맥락을 유지하기 위한 메모리 시스템을 포함합니다.\n",
      "5. **Indexes**: 문서 검색을 위한 인덱싱 도구를 제공합니다.\n",
      "6. **Agents**: 도구를 사용하여 복잡한 작업을 수행하는 에이전트입니다.\n",
      "참조문서 : ['langchain_intro.txt', 'langchain_intro.txt', 'langchain_intro.txt']\n",
      "소요된 시간 : 2.758018970489502\n",
      "테스트 질문3 : VectorDB에는 어떤 종류가 있나요?\n",
      "답변 : 제공된 문서에서 해당 정보를 찾을 수 없습니다.\n",
      "참조문서 : ['vectordb_intro.txt', 'vectordb_intro.txt', 'vectordb_intro.txt']\n",
      "소요된 시간 : 1.098820686340332\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "체인구조\n",
    "질문-> retriever            --> 관련 문서 검색\n",
    "        format_docs         --> 문자열로 변환\n",
    "        prompt              --> context + question 결합\n",
    "        llm                 --> 답변생성\n",
    "        strparser           --> 문자열 출력\n",
    "'''\n",
    "\n",
    "print('RAG 체인 테스트')\n",
    "test_questions = [\n",
    "    \"RAG란 무엇이고 어떤 장점이 있나요?\",\n",
    "    \"LangChain의 주요 구성 요소를 설명해주세요.\",\n",
    "    \"VectorDB에는 어떤 종류가 있나요?\",\n",
    "]\n",
    "for i, question in enumerate(test_questions,1) :\n",
    "    print(f'테스트 질문{i} : {question}')\n",
    "    start_time = time.time()\n",
    "    # RAG체인 실행\n",
    "    answer = rag_chain.invoke(question)  #LCEL로 하면 전부 invoke.. invoke가 뭔데?\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f'답변 : {answer}')\n",
    "    # 참조문서\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    sources = [doc.metadata.get('source', 'unknown') for doc in retrieved_docs]\n",
    "    print(f'참조문서 : {sources}')\n",
    "    print(f'소요된 시간 : {elapsed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c5e27ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG 고급 패턴\n",
      "query transformaton \n",
      "    원본 : RAG가 뭔지 좀 알려주세요\n",
      "    변환 : RAG 정의 및 의미\n"
     ]
    }
   ],
   "source": [
    "# 고급 RAG 사용\n",
    "print('RAG 고급 패턴')\n",
    "\n",
    "print('query transformaton ')\n",
    "query_transform_prompt = ChatPromptTemplate.from_template(\n",
    "    '''다음 질문을 검색에 더 적합한 형태로 변환해주세요.\n",
    "    키워드 중심으로 명확하게 바꿔주세요\n",
    "\n",
    "    원본질문:{question}\n",
    "\n",
    "    변환된 검색어 (한 줄로):'''\n",
    ")\n",
    "query_chain = query_transform_prompt | llm | StrOutputParser()\n",
    "\n",
    "orginal_question = 'RAG가 뭔지 좀 알려주세요'\n",
    "transformed = query_chain.invoke({'question':orginal_question })\n",
    "print(f'    원본 : {orginal_question}')\n",
    "print(f'    변환 : {transformed}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
