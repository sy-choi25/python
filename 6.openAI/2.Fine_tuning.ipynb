{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eb1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac24c5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SAMSUNG\\miniconda3\\envs\\openai\\Lib\\site-packages\\huggingface_hub\\file_download.py:121: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\SAMSUNG\\.cache\\huggingface\\hub\\datasets--beomi--KoAlpaca-v1.1a. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 21155/21155 [00:00<00:00, 109123.50 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'output', 'url'],\n",
       "        num_rows: 21155\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"beomi/KoAlpaca-v1.1a\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f32d39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bff2239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스웨터의 유래는 어디에서 시작되었나요?\n",
      "스웨터의 유래는 14세기경 북유럽항구지역에서 어망을 짜던 기술을 의복에 활용하면서 시작되었습니다. 노동자들의 방한복에서 시작된 스웨터는 여가생활과 스포츠의 붐에 힘입어 대중화되었습니다. 이후, 겨울철 이너웨어의 대명사가 되었습니다. 스웨터는 짜서(Knit) 만든 옷을 말하며, 어부들의 방한복으로 짜여졌던 스웨터 중에서도 스코틀랜드 해안지방의 여인들은 바다로 나가는 남편이나 연인, 자식들에게 무사히 돌아올 것을 기원하며 로프나 닻 무늬를 정성껏 짜넣었다고 합니다. 그 실용성과 정성이 오늘에까지 이어지고 있습니다.\n",
      "https://kin.naver.com/qna/detail.naver?d1id=11&dirId=11080102&docId=47833655\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train']['instruction'][1])\n",
    "print(dataset['train']['output'][1])\n",
    "print(dataset['train']['url'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa4a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai 파인튜니\n",
    "# sft(Supervised Fine-Tuning) 포멧\n",
    "# json\n",
    "\n",
    "{\n",
    "    \"messages\" : [\n",
    "    {'role':'user', 'content' : '질문'},\n",
    "    {'role':'assistant', 'content' : '정답'}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5ecce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "outpot_file = 'KoAlpaca.jsonl' # jsonl : 제이슨 형태를 리스트로 만들어 놓은것\n",
    "with open(outpot_file,'w', encoding='utf-8') as f:\n",
    "    for data in dataset['train'] :\n",
    "        data['instruction']\n",
    "        data['output']\n",
    "        data = {\n",
    "            \"messages\" : [\n",
    "                {'role':'user', 'content' : data['instruction']},       # user 사용자의 질문\n",
    "                {'role':'assistant', 'content' : data['output']}        # assistant 시스템이 정답을 말하는거\n",
    "              ]\n",
    "        }\n",
    "        f.write(json.dumps(data,ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ae2708d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "업로드된 파일 id : file-9gzYiZvk8KZ1fTtLdcE76H\n"
     ]
    }
   ],
   "source": [
    "# openai에 업로드\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "file = client.files.create(\n",
    "    file = open('KoAlpaca.jsonl','rb'),\n",
    "    purpose= 'fine-tune')\n",
    "print(f'업로드된 파일 id : {file.id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "094549b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파인튜닝 job id = ftjob-dLXgoKRycGfKQUslZ0vPOGsV\n"
     ]
    }
   ],
   "source": [
    "# 파인튜닝\n",
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file = file.id,\n",
    "    model= 'gpt-4o-mini-2024-07-18'\n",
    ")\n",
    "print(f'파인튜닝 job id = {job.id}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
