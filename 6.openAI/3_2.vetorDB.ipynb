{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f46bc6",
   "metadata": {},
   "source": [
    "<span style=\"color: gold;\"> 벡터 DB = 벡터 스토어\n",
    "\n",
    "<span style=\"font-size:13px;\">\n",
    "\n",
    "- 텍스트·이미지 등을 벡터로 저장하고, 유사도 기반으로 검색하는 DB를 통칭하는 말\n",
    "- 데이터베이스는 쿼리가 정확하게 일치해야지 결과를 출력한다 ( 대한민국 =! 한국 -> 다르게 인식)\n",
    "- 벡터DB는 단어의 의미와 맥락을 기반으로 데이터를 찾는다\n",
    "- 벡터 단위의 유사도를 보고 출력해주는 것 중에 하나가  <span style=\"color: yellow\">크로마DB(ChromaDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35327325",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a8b409",
   "metadata": {},
   "source": [
    "<span style=\"color: gold;\"> 1. 기본 ChromaDB 임베딩 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df81af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAMSUNG\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:20<00:00, 4.03MiB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['732aeb38-f83c-49b6-bebc-8d7112ff5035']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['글자를 입력하는 키보드']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'category': 'input'}]],\n",
       " 'distances': [[0.6260867714881897]]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 임베딩을 따로 정의안하고 기본으로 사용한 chromadb  \n",
    "\n",
    "import chromadb\n",
    "# 1. 클라이언트 생성 (메모리에만 저장)\n",
    "client = chromadb.Client() #--> 인메모리 방식 / 객체를 만들었다라고 생각\n",
    "\n",
    "# 2. 컬렉션 생성  (데이터베이스에 스키마, 테이블.. 같은걸 만들었다 생각)\n",
    "collection = client.get_or_create_collection('my_collection')  # get_or_create_collection 있으면 가져오고 없으면 만들어라/ 컬렉션 이름운 유니크해야 함\n",
    "\n",
    "# 3. 데이터를 추가\n",
    "import uuid\n",
    "collection.add(\n",
    "    documents = ['화면을 보여주는 모니터', '글자를 입력하는 키보드', '커서를 움직이는 마우스'], # 저장할 텍스트(임베딩될 문장)\n",
    "    metadatas = [{'category' : 'display'}, {'category':'input'}, {'category': 'input'}], # 문장에 붙일추가 정보 (옵션)\n",
    "    ids = [str(uuid.uuid4()), str(uuid.uuid4()), str(uuid.uuid4())]       # 필수, 각 문서의 고유 식별자. ids는 문자열만 허용해서 str()씌워줌\n",
    ")\n",
    "\n",
    "# 4. 질문하기 (의미기반)\n",
    "results = collection.query(\n",
    "    query_texts=['숫자를 입력하는 기계'],\n",
    "    n_results= 1 #결과 하나만\n",
    ")\n",
    "\n",
    "results\n",
    "\n",
    "# 결과가 좋지 않음. chromadb가 한국어가 별로임 # default languge 를 사용해서.\n",
    "    # query_texts=['뭔가를 보여주는 기계'], ---> 출력  'documents': [['커서를 움직이는 마우스']],\n",
    "    # query_texts=['숫자를 입력하는 기계'] ---> 출력 'documents': [['글자를 입력하는 키보드']],"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b97efd",
   "metadata": {},
   "source": [
    "<span style=\"color: gold;\">  2. OpenAI을 사용한 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea784c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['018f78d0-5892-494b-a282-416ef56e979b']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['화면을 보여주는 모니터']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'category': 'display'}]],\n",
       " 'distances': [[0.5194305777549744]]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# 1. 클라이언트 생성 (메모리에만 저장)\n",
    "\n",
    "client = chromadb.Client() #--> 인메모리 방식 / 객체를 만들었다라고 생각\n",
    "embed_fn = OpenAIEmbeddingFunction( \n",
    "            api_key= os.environ['OPENAI_API_KEY'],\n",
    "            model_name=\"text-embedding-3-small\"\n",
    "        )\n",
    "    \n",
    "\n",
    "# 2. 컬렉션 생성  (데이터베이스에 스키마, 테이블.. 같은걸 만들었다 생각)\n",
    "collection = client.get_or_create_collection('my_collection2', embedding_function=embed_fn)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. 데이터를 추가\n",
    "import uuid\n",
    "collection.add(\n",
    "    documents = ['화면을 보여주는 모니터', '글자를 입력하는 키보드', '커서를 움직이는 마우스'], # 벡터가 될 문장\n",
    "    metadatas = [{'category' : 'display'}, {'category':'input'}, {'category': 'input'}], # 문장들과 같이 사용할 .. ? 인덱스화 됐다  #필수아니고, 옵션.\n",
    "    ids = [str(uuid.uuid4()), str(uuid.uuid4()), str(uuid.uuid4())]       # 필수, 각각의 고유번호. ids는 str만 허용해서 str()씌워줌\n",
    ")\n",
    "\n",
    "# 4. 질문하기 (의미기반)\n",
    "results = collection.query(\n",
    "    query_texts=['뭔가를 보여주는 기계'],\n",
    "    n_results= 1 #결과 하나만\n",
    ")\n",
    "\n",
    "results\n",
    "\n",
    "# 결과 나아짐\n",
    "    # query_texts=['뭔가를 보여주는 기계'], ---> 출력   'documents': [['화면을 보여주는 모니터']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983af84e",
   "metadata": {},
   "source": [
    "<span style=\"color: gold;\">  3. 허깅페이스의 모델을 사용한 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074c8199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\SAMSUNG\\miniconda3\\envs\\llm_env\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f98c09d1bae4477ac0e521b2639778b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SAMSUNG\\miniconda3\\envs\\llm_env\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\SAMSUNG\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0e12aca0154a19ae956984626dc803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d1edc2e73840a69158e928a26130b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e8aa193bb34e14b8b5fc61622a6344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773ca6683bf74e298ef7c24f416df949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5cd9dae3134a618d3a381417108e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca822ea63814fcda19ba1544a7699cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002c9a8c592847ceaf6395860e3b764d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588fa22618404419b41e580899a9a8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e413778562d41c69dc254360796f33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'ids': [['14f6681e-4595-42fc-8e56-0a1b0a105ef2']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['커서를 움직이는 마우스']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'category': 'input'}]],\n",
       " 'distances': [[0.2587946653366089]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hugging Face 의  model_name= \"paraphrase-multilingual-MiniLM-L12-v2\" 임베딩 사용\n",
    "\n",
    "\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# 1. 클라이언트 생성 (메모리에만 저장)\n",
    "\n",
    "client = chromadb.Client() \n",
    "\n",
    "from chromadb.utils import embedding_functions\n",
    "embed_fn = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "            model_name= \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")\n",
    "    \n",
    "\n",
    "# 2. 컬렉션 생성  (데이터베이스에 스키마, 테이블.. 같은걸 만들었다 생각)\n",
    "collection = client.get_or_create_collection('my_collection3', embedding_function=embed_fn)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. 데이터를 추가\n",
    "import uuid\n",
    "collection.add(\n",
    "    documents = ['화면을 보여주는 모니터', '글자를 입력하는 키보드', '커서를 움직이는 마우스'], # 벡터가 될 문장\n",
    "    metadatas = [{'category' : 'display'}, {'category':'input'}, {'category': 'input'}], # 문장들과 같이 사용할 .. ? 인덱스화 됐다  #필수아니고, 옵션.\n",
    "    ids = [str(uuid.uuid4()), str(uuid.uuid4()), str(uuid.uuid4())]       # 필수, 각각의 고유번호. ids는 str만 허용해서 str()씌워줌\n",
    ")\n",
    "\n",
    "# 4. 질문하기 (의미기반)\n",
    "results = collection.query(\n",
    "    query_texts=['뭔가를 보여주는 기계'],\n",
    "    n_results= 1 #결과 하나만\n",
    ")\n",
    "\n",
    "results\n",
    "\n",
    "# 결과 좋지 않음\n",
    "    # query_texts=['뭔가를 보여주는 기계'], ---> 출력  'documents': [['커서를 움직이는 마우스']],"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a661ed4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
