{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e521161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as ply\n",
    "import sys, os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c88b903",
   "metadata": {},
   "source": [
    "<span style=\"color: Gold\"> 1. 패치분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4f9d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 이미지 크기 : 224 x 224\n",
      " 패치 크기 : 16 x 16\n",
      " 채널 수 : 3\n",
      " 패치 수 : 14 x14\n",
      " 더미 이미지 생성\n",
      " 입력 이미지 shape : torch.Size([1, 3, 224, 224])\n",
      " \n",
      " 패치 임베딩 후\n",
      " conv2d 출력 shape : torch.Size([1, 768, 14, 14])\n",
      " Flatten 후 shape : torch.Size([1, 196, 768])\n",
      " \n",
      " 패치 수  : 196\n",
      " 각 패치의 임베딩 차원 수  : 768\n"
     ]
    }
   ],
   "source": [
    "def patch_embedding():\n",
    "    '''이미지를 패치로 분할하는 과정(patch embedding)'''\n",
    "    # 설정\n",
    "    image_size = 224\n",
    "    patch_size = 16\n",
    "    channels = 3\n",
    "    embedding_dim = 768\n",
    "\n",
    "    # 패치수 계산\n",
    "    num_patchs = (image_size // patch_size) **2\n",
    "    print(f' 이미지 크기 : {image_size} x {image_size }')\n",
    "    print(f' 패치 크기 : {patch_size} x {patch_size }')\n",
    "    print(f' 채널 수 : {channels}')\n",
    "    print(f' 패치 수 : {image_size // patch_size} x{image_size // patch_size}')\n",
    "\n",
    "    # 더미 이미지 생성\n",
    "    dummy_image = torch.randn(1,channels, image_size, image_size)\n",
    "    print(f' 더미 이미지 생성')\n",
    "    print(f' 입력 이미지 shape : {dummy_image.shape}') # [1,3,224,224]\n",
    "\n",
    "    # 패치분할(conv2 사용)\n",
    "    # conv2 stride = patch_size 겹치지 않는 패치 추출 / # stride = 커널이 한 번에 몇 칸씩 이동하느냐\n",
    "    patch_embed = nn.Conv2d(in_channels=channels, out_channels=embedding_dim, kernel_size=patch_size, stride=patch_size) # 입력하는 채널의 수, 출력하는 채널의 수, kernel_size -> 몇개씩 도장을 찍느냐, stride -> 이동 간격\n",
    "\n",
    "    # 패치 임베딩 적용\n",
    "    patches = patch_embed(dummy_image)\n",
    "    print(f' \\n 패치 임베딩 후')\n",
    "    print(f' conv2d 출력 shape : {patches.shape}') # [1, 768, 14, 14]\n",
    "\n",
    "    # Flatten : (배치사이즈(B), 임베딩 차이(D), 이미지 높이(H), 이미지 넓이(W)) -> (B, 196(HxW), D) -> (1, 196, 768)\n",
    "    patches_flat = patches.flatten(2).transpose(1,2)\n",
    "    print(f' Flatten 후 shape : {patches_flat.shape}') # [1, 196, 768]\n",
    "\n",
    "    # 각 패치는 768차원 벡터\n",
    "    print(f' \\n 패치 수  : {patches_flat.shape[1]}')\n",
    "    print(f' 각 패치의 임베딩 차원 수  : {patches_flat.shape[2]}')\n",
    "    return patches_flat\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    patch_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d943f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위치 임베딩의 역할\n",
    "def positional_embedding():\n",
    "    '''위치 임베딩'''\n",
    "    num_patches = 196\n",
    "    embedding_dim = 768\n",
    "\n",
    "    # 위치 임베딩 생성  \n",
    "    # 이 텐서는 학습대상 Optimizer 에 의해 업데이트\n",
    "    position_embedding = nn.Parameter(torch.randn(1, num_patches+1, embedding_dim)) # num_patches+1 -> +1을 하는 이유는 cls 토큰을 추가하기 위해서\n",
    "    print(f' 위치 임베딩 shape : {position_embedding.shape}')\n",
    "    print(f' 총 위치 수 : {num_patches+1} (패치 196 + cls 토큰 1개)')\n",
    "\n",
    "    # 배치 차원 제거 -> 각 위치를 하나의 벡터로 다루기 위해 배치 크기가 1인 형태는 분석 시 불필요\n",
    "    pos_emb = position_embedding.squeeze(0) #squeeze(0)-> 첫번째(배치크기)를 숨긴다"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
