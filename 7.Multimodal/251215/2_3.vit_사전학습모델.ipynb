{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb055976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface transformer vit\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc1650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_huggingface_vit():\n",
    "    '''huggingface transformers vit'''\n",
    "    try:\n",
    "        from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "        # 모델과 프로세스 로드\n",
    "        model_name = 'google/vit-base-patch16-224'\n",
    "        processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "        model = ViTForImageClassification.from_pretrained(model_name)\n",
    "        model.eval()\n",
    "        print(f'\\n[모델 정보]')\n",
    "        print(f'파라메터수 : { sum(p.numel()  for p in model.parameters())}')\n",
    "        print(f'클래스 수 : { model.config.num_channels}')\n",
    "        print(f'이미지 크기 : { model.config.image_size}')\n",
    "        print(f'패치 크기 : { model.config.patch_size}')\n",
    "        print(f'히든 크기 : { model.config.hidden_size}')\n",
    "        print(f'레이어 수 : { model.config.num_hidden_layers}')\n",
    "        print(f'어텐션 해드 수 : { model.config.num_attention_heads}')\n",
    "        return model, processor\n",
    "    except Exception as e:\n",
    "        print(f' hugging face vit 로드 실패 : {e}')\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d1680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[모델 정보]\n",
      "파라메터수 : 86567656\n",
      "클래스 수 : 3\n",
      "이미지 크기 : 224\n",
      "패치 크기 : 16\n",
      "히든 크기 : 768\n",
      "레이어 수 : 12\n",
      "어텐션 해드 수 : 12\n",
      "    - vit_base_patch16_224.augreg2_in21k_ft_in1k\n",
      "    - vit_base_patch16_224.augreg_in1k\n",
      "    - vit_base_patch16_224.augreg_in21k\n",
      "    - vit_base_patch16_224.augreg_in21k_ft_in1k\n",
      "    - vit_base_patch16_224.dino\n",
      "    - vit_base_patch16_224.mae\n",
      "    - vit_base_patch16_224.orig_in21k\n",
      "    - vit_base_patch16_224.orig_in21k_ft_in1k\n",
      "    - vit_base_patch16_224.sam_in1k\n",
      "    - vit_base_patch16_224_miil.in21k\n",
      "    - vit_base_patch16_224_miil.in21k_ft_in1k\n",
      "총   333개 모델\n",
      "실제 다운로드 모델명 : vit_base_patch16_224.augreg2_in21k_ft_in1k\n"
     ]
    }
   ],
   "source": [
    "# timm 라이브러리를 사용한 vit\n",
    "def use_timm_vit():\n",
    "    '''timm 라이브러리 vit'''    \n",
    "    import timm\n",
    "    # 사용가능한 vit 모델 목록\n",
    "    vit_models = timm.list_models('vit*', pretrained=True)\n",
    "    for model_name in vit_models:\n",
    "        if 'vit_base_patch16_224' in model_name:\n",
    "            print(f'    - {model_name}')\n",
    "    print(f'총   {len(vit_models)}개 모델')\n",
    "\n",
    "    model = timm.create_model('vit_base_patch16_224',pretrained=True)\n",
    "    print(f\"실제 다운로드 모델명 : vit_base_patch16_224.{model.default_cfg['tag']}\")\n",
    "\n",
    "    # timm의 데이터 설정 가져오기\n",
    "    data_config = timm.data.resolve_model_data_config(model)\n",
    "    transform = timm.data.create_transform(**data_config,is_training = False)\n",
    "    return  model, transform\n",
    "\n",
    "def classify_image_hf(model, processor, image):\n",
    "    \"\"\"Hugging Face 모델로 이미지 분류\"\"\"\n",
    "    \n",
    "    if model is None:\n",
    "        print(\"  모델이 로드되지 않았습니다.\")\n",
    "        return None\n",
    "    \n",
    "    # 이미지 전처리\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    print(f\"\\n[전처리된 입력]\")\n",
    "    print(f\"  pixel_values shape: {inputs['pixel_values'].shape}\")\n",
    "    \n",
    "    # 추론\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    print(f\"\\n[모델 출력]\")\n",
    "    print(f\"  logits shape: {logits.shape}\")\n",
    "    \n",
    "    # Top-5 예측\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    top5_probs, top5_indices = torch.topk(probs, 5)\n",
    "    \n",
    "    print(f\"\\n[Top-5 예측 결과]\")\n",
    "    for i, (prob, idx) in enumerate(zip(top5_probs[0], top5_indices[0])):\n",
    "        label = model.config.id2label[idx.item()]\n",
    "        print(f\"  {i+1}. {label}: {prob.item():.4f} ({prob.item()*100:.2f}%)\")\n",
    "    \n",
    "    return top5_probs[0], top5_indices[0]\n",
    "\n",
    "def classify_image_timm(model, transform, image):\n",
    "    \"\"\"timm 모델로 이미지 분류\"\"\" \n",
    "    \n",
    "    if model is None:\n",
    "        print(\"  모델이 로드되지 않았습니다.\")\n",
    "        return None\n",
    "    \n",
    "    # 이미지 전처리\n",
    "    img_tensor = transform(image).unsqueeze(0)\n",
    "    print(f\"\\n[전처리된 입력]\")\n",
    "    print(f\"  tensor shape: {img_tensor.shape}\")\n",
    "    \n",
    "    # 추론\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "    \n",
    "    print(f\"\\n[모델 출력]\")\n",
    "    print(f\"  outputs shape: {outputs.shape}\")\n",
    "    \n",
    "    # Top-5 예측\n",
    "    probs = F.softmax(outputs, dim=-1)\n",
    "    top5_probs, top5_indices = torch.topk(probs, 5)\n",
    "    \n",
    "    # ImageNet 클래스 이름 로드\n",
    "    try:\n",
    "        url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "        response = requests.get(url, timeout=10)\n",
    "        categories = [s.strip() for s in response.text.splitlines()]\n",
    "        \n",
    "        print(f\"\\n[Top-5 예측 결과]\")\n",
    "        for i, (prob, idx) in enumerate(zip(top5_probs[0], top5_indices[0])):\n",
    "            label = categories[idx.item()] if idx.item() < len(categories) else f\"class_{idx.item()}\"\n",
    "            print(f\"  {i+1}. {label}: {prob.item():.4f} ({prob.item()*100:.2f}%)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n[Top-5 예측 결과 (인덱스)]\")\n",
    "        for i, (prob, idx) in enumerate(zip(top5_probs[0], top5_indices[0])):\n",
    "            print(f\"  {i+1}. class_{idx.item()}: {prob.item():.4f} ({prob.item()*100:.2f}%)\")\n",
    "    \n",
    "    return top5_probs[0], top5_indices[0]\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # 모델, 프리프로세스 로드(huggingfase, timm)\n",
    "    hf_model, hf_process = use_huggingface_vit()\n",
    "    timm_model, timm_process = use_timm_vit()\n",
    "    # 샘플이미지 확보\n",
    "    # hf에서 받은 모델, timm에서 받은 모델로 전용 추론함수에 넣어서 결과를 확인(ex classify_image_timm((timm_model,timm_process,img))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "823888b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== timm ViT 결과 =====\n",
      "\n",
      "[전처리된 입력]\n",
      "  tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "[모델 출력]\n",
      "  outputs shape: torch.Size([1, 1000])\n",
      "\n",
      "[Top-5 예측 결과]\n",
      "  1. tiger cat: 0.6027 (60.27%)\n",
      "  2. Egyptian cat: 0.1188 (11.88%)\n",
      "  3. tabby: 0.0718 (7.18%)\n",
      "  4. lynx: 0.0218 (2.18%)\n",
      "  5. swab: 0.0161 (1.61%)\n",
      "\n",
      "===== HuggingFace ViT 결과 =====\n",
      "\n",
      "[전처리된 입력]\n",
      "  pixel_values shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "[모델 출력]\n",
      "  logits shape: torch.Size([1, 1000])\n",
      "\n",
      "[Top-5 예측 결과]\n",
      "  1. tiger cat: 0.4328 (43.28%)\n",
      "  2. tabby, tabby cat: 0.2598 (25.98%)\n",
      "  3. Egyptian cat: 0.1613 (16.13%)\n",
      "  4. broom: 0.0122 (1.22%)\n",
      "  5. swab, swob, mop: 0.0077 (0.77%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.4328, 0.2598, 0.1613, 0.0122, 0.0077]),\n",
       " tensor([282, 281, 285, 462, 840]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "image_path = \"C:/python_src/7.Multimodal/251215/download_img/Cat.jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "print(\"\\n===== timm ViT 결과 =====\")\n",
    "classify_image_timm(timm_model, timm_process, image)\n",
    "\n",
    "print(\"\\n===== HuggingFace ViT 결과 =====\")\n",
    "classify_image_hf(hf_model, hf_process, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd42237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[모델 정보]\n",
      "파라메터수 : 86567656\n",
      "클래스 수 : 3\n",
      "이미지 크기 : 224\n",
      "패치 크기 : 16\n",
      "히든 크기 : 768\n",
      "레이어 수 : 12\n",
      "어텐션 해드 수 : 12\n",
      "    - vit_base_patch16_224.augreg2_in21k_ft_in1k\n",
      "    - vit_base_patch16_224.augreg_in1k\n",
      "    - vit_base_patch16_224.augreg_in21k\n",
      "    - vit_base_patch16_224.augreg_in21k_ft_in1k\n",
      "    - vit_base_patch16_224.dino\n",
      "    - vit_base_patch16_224.mae\n",
      "    - vit_base_patch16_224.orig_in21k\n",
      "    - vit_base_patch16_224.orig_in21k_ft_in1k\n",
      "    - vit_base_patch16_224.sam_in1k\n",
      "    - vit_base_patch16_224_miil.in21k\n",
      "    - vit_base_patch16_224_miil.in21k_ft_in1k\n",
      "총   333개 모델\n",
      "실제 다운로드 모델명 : vit_base_patch16_224.augreg2_in21k_ft_in1k\n",
      "\n",
      "\n",
      "[ timm 추론]...\n",
      "\n",
      "[전처리된 입력]\n",
      "  tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "[모델 출력]\n",
      "  outputs shape: torch.Size([1, 1000])\n",
      "\n",
      "[Top-5 예측 결과]\n",
      "  1. bulbul: 0.3902 (39.02%)\n",
      "  2. water ouzel: 0.0643 (6.43%)\n",
      "  3. brambling: 0.0623 (6.23%)\n",
      "  4. goldfinch: 0.0567 (5.67%)\n",
      "  5. jacamar: 0.0466 (4.66%)\n",
      "\n",
      "[전처리된 입력]\n",
      "  tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "[모델 출력]\n",
      "  outputs shape: torch.Size([1, 1000])\n",
      "\n",
      "[Top-5 예측 결과]\n",
      "  1. tiger cat: 0.6027 (60.27%)\n",
      "  2. Egyptian cat: 0.1188 (11.88%)\n",
      "  3. tabby: 0.0718 (7.18%)\n",
      "  4. lynx: 0.0218 (2.18%)\n",
      "  5. swab: 0.0161 (1.61%)\n",
      "\n",
      "[전처리된 입력]\n",
      "  tensor shape: torch.Size([1, 3, 224, 224])\n",
      "\n",
      "[모델 출력]\n",
      "  outputs shape: torch.Size([1, 1000])\n",
      "\n",
      "[Top-5 예측 결과]\n",
      "  1. Labrador retriever: 0.8531 (85.31%)\n",
      "  2. golden retriever: 0.0196 (1.96%)\n",
      "  3. Chesapeake Bay retriever: 0.0057 (0.57%)\n",
      "  4. dingo: 0.0035 (0.35%)\n",
      "  5. tennis ball: 0.0023 (0.23%)\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    from glob import glob\n",
    "    # 모델, 프리프로세스 로드(huggingface, timm)\n",
    "    hf_model, hf_process = use_huggingface_vit()\n",
    "    timm_model, timm_process = use_timm_vit()\n",
    "    # 셈플이미지 확보\n",
    "    # hf 에서 받은 모델, timm에서 받은 모델로 전용 추론함수에 넣어서 결과를 확인 (ex classify_image_timm(timm_model,timm_process,img)   )\n",
    "    file_paths = 'C:/python_src/7.Multimodal/251215/download_img'\n",
    "    files = glob(file_paths+'/*.jpg')\n",
    "    print('\\n\\n[ timm 추론]...')\n",
    "    for file in files:\n",
    "        test_img = Image.open(file).convert('RGB')\n",
    "        classify_image_timm(timm_model,timm_process,test_img)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
