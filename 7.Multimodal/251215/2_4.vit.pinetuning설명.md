# ViT 파인튜닝 (Fine-tuning)

## 데이터셋 안내

이 실습에서는 **CIFAR-10** 데이터셋을 사용합니다.

### 자동 다운로드
실습 코드 실행 시 `torchvision`이 자동으로 CIFAR-10 데이터셋을 다운로드합니다.
```python
# 코드 내부에서 자동 다운로드 (download=True)
datasets.CIFAR10(root='./data', train=True, download=True)
```

### 수동 다운로드 (선택사항)
네트워크 문제가 있는 경우 수동으로 다운로드할 수 있습니다:
1. [CIFAR-10 공식 페이지](https://www.cs.toronto.edu/~kriz/cifar.html) 접속
2. "CIFAR-10 python version" 다운로드 (~163MB)
3. `2.middle/data/` 폴더에 압축 해제

> **참고**: GitHub 용량 제한(100MB)으로 인해 데이터셋은 저장소에 포함되지 않습니다.
> 코드 실행 시 자동으로 다운로드됩니다.

---

## 1. 파인튜닝이란?

### 1.1 개념
파인튜닝(Fine-tuning)은 대규모 데이터셋에서 사전 학습된 모델을 특정 작업이나 도메인에 맞게 추가 학습시키는 기법입니다.

**핵심 아이디어**: 일반적인 시각적 특징을 이미 학습한 모델을 활용하여, 적은 데이터와 계산 비용으로 새로운 작업에 적용

### 1.2 Transfer Learning vs Fine-tuning

전이 학습(Transfer Learning)은 큰 개념이고, 파인튜닝(Fine-tuning)은 그 중 하나의 구체적인 방법입니다.

| 구분 | Transfer Learning | Fine-tuning |
|-----|-------------------|-------------|
| 정의 | 사전학습 모델 활용 전반 | 전이학습의 한 방법 |
| 학습 범위 | 분류 헤드만 학습 가능 | 전체 또는 일부 레이어 학습 |
| 데이터 요구량 | 매우 적음 | 적음~중간 |
| 계산 비용 | 낮음 | 중간 |

### 1.3 왜 파인튜닝이 효과적인가?

1. **특징 재사용**: 저수준 특징(엣지, 텍스처)은 대부분의 이미지 작업에 공통
2. **정규화 효과**: 사전학습 가중치가 좋은 초기화 역할
3. **데이터 효율성**: 적은 데이터로도 높은 성능 달성
4. **학습 안정성**: 수렴이 빠르고 안정적

---

## 2. ViT 파인튜닝 전략

### 2.1 전략 1: Linear Probing (Feature Extraction)

**늹징**:
- Transformer Encoder 동결 (학습 않 함)
- Classification Head만 학습
- 가장 적은 계산 비용
- 매우 적은 데이터에 적합

![Linear Probing (Feature Extraction)](./img/Linear%20Probing%20(Feature%20Extraction).png)

**선택 기준**:
- 데이터 양이 적으면 → Linear Probing
- 데이터 양이 충분하고 도메인이 다르면 → Full Fine-tuning

```python
# Linear Probing 예시
for param in model.vit.parameters():
    param.requires_grad = False  # Encoder 동결

# Classification head만 학습
for param in model.classifier.parameters():
    param.requires_grad = True
```

**적합한 경우**:
- 데이터가 매우 적을 때 (수백 장)
- 사전학습 도메인과 유사할 때
- 빠른 실험이 필요할 때

### 2.2 전략 2: Full Fine-tuning

**특징**:
- 전체 모델 학습
- 높은 성능 달성 가능
- 많은 계산 비용
- 과적합 위험

> **참고**: 위 그림의 오른쪽(2. Full Fine-tuning)을 참조하세요.

```python
# Full Fine-tuning 예시
for param in model.parameters():
    param.requires_grad = True  # 전체 학습

# 작은 learning rate 사용
optimizer = AdamW(model.parameters(), lr=1e-5)
```

**적합한 경우**:
- 충분한 데이터가 있을 때 (수천 장 이상)
- 사전학습 도메인과 다를 때
- 최고 성능이 필요할 때

### 2.3 전략 3: Layer-wise Learning Rate Decay (LLRD)

**특징**:
- <span style="color: yellow">각 레이어마다 다른 learning rate 적용 </span>
- 낮은 레이어: 낮은 lr (일반적 특징)
- 깊은 레이어: 높은 lr (태스크 특화 특징)

![Layer-wise Learning Rate Decay (LLRD)](./img/Layer-wise%20Learning%20Rate%20Decay%20(LLRD).png)

**LLRD 공식**: `lr_layer = base_lr × (decay ^ (num_layers - layer_idx))`

```python
# LLRD 예시
def get_layer_lr(layer_idx, base_lr, decay=0.8, num_layers=12):
    return base_lr * (decay ** (num_layers - layer_idx))

# Layer 0: lr * 0.8^12 ≈ lr * 0.069
# Layer 6: lr * 0.8^6 ≈ lr * 0.262
# Layer 11: lr * 0.8^1 = lr * 0.8
```

**장점**:
- 사전학습 지식 보존
- 과적합 방지
- 안정적인 학습

### 2.4 전략 4: Gradual Unfreezing

**특징**:
- 점진적으로 레이어 해동
- 처음에는 head만 학습
- 이후 점점 더 많은 레이어 학습

```python
# Gradual Unfreezing 예시
# Epoch 1-2: Head만 학습
# Epoch 3-4: Head + 마지막 2개 블록
# Epoch 5+: 전체 모델
```

---

## 3. 하이퍼파라미터 가이드

### 3.1 Learning Rate

| 전략 | Learning Rate | 비고 |
|-----|--------------|------|
| Linear Probing | 1e-3 ~ 1e-2 | Head만 학습 |
| Full Fine-tuning | 1e-5 ~ 5e-5 | 전체 학습 |
| LLRD | 1e-4 (base) | Decay 0.65~0.9 |

### 3.2 Batch Size

- **작은 데이터셋**: 16~32
- **중간 데이터셋**: 32~64
- **큰 데이터셋**: 64~256

**메모리 부족 시**:
- Gradient Accumulation 사용
- Mixed Precision (FP16) 사용

### 3.3 Epochs

- **Linear Probing**: 10~30 epochs
- **Full Fine-tuning**: 5~20 epochs

과적합 방지를 위해 Early Stopping 권장

### 3.4 Weight Decay

- 일반적으로 0.01 ~ 0.1
- 과적합 방지 효과
- LayerNorm과 bias에는 적용하지 않는 것이 좋음

### 3.5 Warmup

- 전체 스텝의 5~10%
- Learning rate를 0에서 시작하여 점진적 증가
- 학습 초기 불안정성 방지

```python
# Warmup + Cosine Annealing 스케줄러
scheduler = get_cosine_schedule_with_warmup(
    optimizer,
    num_warmup_steps=100,
    num_training_steps=1000
)
```

---

## 4. 데이터 증강 전략

### 4.1 기본 증강

```python
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean, std),
])
```

### 4.2 고급 증강

#### RandAugment
- 자동으로 최적의 증강 조합 선택
- N개의 증강을 랜덤하게 적용

```python
from torchvision.transforms import RandAugment

transform = transforms.Compose([
    transforms.Resize(256),
    transforms.RandomCrop(224),
    RandAugment(num_ops=2, magnitude=9),
    transforms.ToTensor(),
    transforms.Normalize(mean, std),
])
```

#### Mixup
- 두 이미지와 레이블을 선형 보간

$$\tilde{x} = \lambda x_i + (1-\lambda) x_j$$
$$\tilde{y} = \lambda y_i + (1-\lambda) y_j$$

```python
def mixup(x, y, alpha=0.2):
    lam = np.random.beta(alpha, alpha)
    index = torch.randperm(x.size(0))
    mixed_x = lam * x + (1 - lam) * x[index]
    y_a, y_b = y, y[index]
    return mixed_x, y_a, y_b, lam
```

#### CutMix
- 이미지의 일부를 다른 이미지로 대체

```python
def cutmix(x, y, alpha=1.0):
    lam = np.random.beta(alpha, alpha)
    # 랜덤 박스 영역 계산
    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)
    index = torch.randperm(x.size(0))
    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]
    # 레이블도 면적 비율로 혼합
    lam = 1 - ((bbx2-bbx1)*(bby2-bby1)) / (x.size(-1)*x.size(-2))
    return x, y, y[index], lam
```

### 4.3 정규화 기법

- **Label Smoothing**: 하드 레이블을 소프트 레이블로 변환
- **Dropout**: 랜덤하게 뉴런 비활성화
- **Stochastic Depth**: 랜덤하게 레이어 스킵

---

## 5. 평가 및 모니터링

### 5.1 평가 지표

| 지표 | 설명 | 사용 경우 |
|-----|------|----------|
| Accuracy | 정확도 | 균형 데이터셋 |
| F1-Score | 정밀도와 재현율의 조화 평균 | 불균형 데이터셋 |
| Confusion Matrix | 클래스별 성능 분석 | 상세 분석 |
| Top-5 Accuracy | 상위 5개 예측 중 정답 | 다중 클래스 |

### 5.2 학습 모니터링

**TensorBoard 사용**:
```python
from torch.utils.tensorboard import SummaryWriter

writer = SummaryWriter('runs/vit_finetune')
writer.add_scalar('Loss/train', loss, epoch)
writer.add_scalar('Accuracy/val', acc, epoch)
```

**모니터링 항목**:
- Training Loss
- Validation Loss
- Validation Accuracy
- Learning Rate
- Gradient Norm

### 5.3 Early Stopping

```python
class EarlyStopping:
    def __init__(self, patience=5, delta=0.001):
        self.patience = patience
        self.delta = delta
        self.counter = 0
        self.best_score = None
        self.early_stop = False
    
    def __call__(self, val_loss):
        score = -val_loss
        if self.best_score is None:
            self.best_score = score
        elif score < self.best_score + self.delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.counter = 0
```

---

## 6. 파인튜닝 체크리스트

### 6.1 데이터 준비
- [ ] 데이터 품질 확인 (노이즈, 라벨 오류)
- [ ] 클래스 불균형 확인
- [ ] Train/Val/Test 분리
- [ ] 데이터 증강 설정

### 6.2 모델 설정
- [ ] 사전학습 모델 선택 (Base, Large, etc.)
- [ ] 파인튜닝 전략 선택
- [ ] Learning rate 및 스케줄러 설정
- [ ] Optimizer 선택 (AdamW 권장)

### 6.3 학습 실행
- [ ] Gradient clipping 설정
- [ ] Mixed precision 설정 (메모리 절약)
- [ ] 체크포인트 저장 설정
- [ ] Early stopping 설정

### 6.4 평가
- [ ] Validation 성능 확인
- [ ] Test 성능 확인
- [ ] Confusion matrix 분석
- [ ] 오분류 샘플 분석

---

## 7. 일반적인 문제와 해결책

### 문제 1: 과적합
**증상**: Train loss ↓, Val loss ↑
**해결책**:
- 데이터 증강 강화
- Weight decay 증가
- Dropout 추가
- 더 작은 모델 사용

### 문제 2: 학습이 안 됨
**증상**: Loss가 감소하지 않음
**해결책**:
- Learning rate 조정 (높이거나 낮추기)
- Gradient clipping 확인
- 데이터 전처리 확인
- 레이블 정확성 확인

### 문제 3: 학습 불안정
**증상**: Loss가 크게 진동
**해결책**:
- Learning rate 낮추기
- Warmup 스텝 늘리기
- Batch size 키우기
- Gradient clipping 적용

### 문제 4: 메모리 부족
**증상**: CUDA out of memory
**해결책**:
- Batch size 줄이기
- Gradient accumulation 사용
- Mixed precision 사용
- 더 작은 모델 사용

---

## 8. 참고 자료

### 논문
- [How to Train ViT? Data, Augmentation, and Regularization](https://arxiv.org/abs/2106.10270)
- [Training data-efficient image transformers](https://arxiv.org/abs/2012.12877) (DeiT)
- [An Image is Worth 16x16 Words](https://arxiv.org/abs/2010.11929) (ViT 원논문)

### 코드
- [Hugging Face ViT Fine-tuning Tutorial](https://huggingface.co/docs/transformers/tasks/image_classification)
- [timm Training Script](https://github.com/huggingface/pytorch-image-models/blob/main/train.py)

### 블로그
- [Fine-Tuning Vision Transformers (Google AI Blog)](https://ai.googleblog.com/)
- [A Guide to Fine-tuning ViT (Hugging Face)](https://huggingface.co/blog)