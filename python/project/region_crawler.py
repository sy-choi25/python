from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
import time
from selenium.webdriver.support.ui import Select

# DB ì €ì¥ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pymysql
from dotenv import load_dotenv
import os


def get_regions_from_website():
    print("--- ì§€ì—­ ëª©ë¡ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤ ---")
    url = 'https://stat.molit.go.kr/portal/cate/statView.do?hRsId=58'
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service)
    
    city_list = []
    
    try:
        driver.get(url)
        driver.maximize_window()
        time.sleep(5)

        # ì‹œë„ë³„ ìë™ì°¨ ë“±ë¡ í˜„í™© ì¡°íšŒ (í˜„ì¬ 'ì„œìš¸'ë§Œ ì„ íƒëœ ìƒíƒœ)
        select = Select(driver.find_element(By.ID, 'sFormId'))
        select.select_by_value('5498') # 'ì„œìš¸'
        time.sleep(0.5)

        form_btn = driver.find_element(By.XPATH, '//*[@id="main"]/div/div[2]/div[2]/div[1]/div[2]/div/button')
        driver.execute_script('arguments[0].click()', form_btn)
        time.sleep(3)

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        
        # ì°¸ê³ : ì´ ì„ íƒìëŠ” ë§¤ìš° êµ¬ì²´ì ì´ì–´ì„œ ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ ì‹œ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        str_table_rows = '#sheet01-table > tbody > tr:nth-child(2) > td:nth-child(1) > div > div.GMPageOne > table > tbody'
        city_rows = soup.select(str_table_rows)

        # ê´‘ì—­ìì¹˜ë‹¨ì²´ì™€ êµ¬ë¥¼ íŠœí”Œ í˜•íƒœë¡œ ë¬¶ì–´ì„œ listì— ì¶”ê°€
        for i in city_rows:
            rlg = ''
            try:
                i_list = i.select('td')
                for j in i_list:
                    # 'ì„œìš¸'ì´ë¼ëŠ” í…ìŠ¤íŠ¸ë¥¼ ë§Œë‚˜ë©´ rlg ë³€ìˆ˜ì— ì €ì¥
                    if j.text.strip() in ['ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°', 'ì„¸ì¢…', 'ê²½ê¸°', 'ì¶©ë¶', 'ì¶©ë‚¨', 'ì „ë‚¨', 'ê²½ë¶', 'ê²½ë‚¨', 'ì œì£¼', 'ê°•ì›', 'ì „ë¶']:
                        rlg = j.text.strip()
                    # ë¹ˆ ê°’ì´ ì•„ë‹ˆë©´ (rlg, ì‹œêµ°êµ¬) í˜•íƒœë¡œ ì¶”ê°€
                    elif j.text.strip() and not '2025' in j.text.strip():
                        city_list.append((rlg, j.text.strip()))
            
            except Exception as e:
                print(f"íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        
        print(f"í¬ë¡¤ë§ ì™„ë£Œ: ì´ {len(city_list)}ê°œì˜ ì§€ì—­ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        print(city_list)
        return city_list

    finally:
        driver.quit()

# ===================================================================
# 2. DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
# ===================================================================
def save_regions_to_db(region_list):
    if not region_list:
        print("ì €ì¥í•  ì§€ì—­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\n--- DBì— ì§€ì—­ ì •ë³´ ì €ì¥ì„ ì‹œì‘í•©ë‹ˆë‹¤ ---")
    load_dotenv()
    db_config = {
        'host': os.getenv("DB_HOST"), 'user': os.getenv("DB_USER"),
        'password': os.getenv("DB_PASSWORD"), 'database': 'sknfirst'
    }

    try:
        conn = pymysql.connect(**db_config)
        cursor = conn.cursor()
        print(f"âœ… MySQL '{db_config['database']}' DBì— ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤!")

        sql = "INSERT IGNORE INTO region (sido, sigungu) VALUES (%s, %s)"
        
        cursor.executemany(sql, region_list)
        conn.commit()
        
        print(f"DB ì €ì¥ ì™„ë£Œ: {cursor.rowcount}ê°œì˜ ìƒˆë¡œìš´ ì§€ì—­ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except pymysql.MySQLError as err:
        print(f"MySQL ì˜¤ë¥˜: {err}")
    finally:
        if 'cursor' in locals():
            cursor.close()
        if 'conn' in locals():
            conn.close()
            print("ğŸ”Œ MySQL ì—°ê²°ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# ===================================================================
# 3. ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
# ===================================================================
if __name__ == '__main__':
    # 1. ë³´ë‚´ì£¼ì‹  ì½”ë“œë¡œ í¬ë¡¤ë§ ì‹¤í–‰
    scraped_regions = get_regions_from_website()
    
    # 2. í¬ë¡¤ë§ ê²°ê³¼ê°€ ìˆìœ¼ë©´ DBì— ì €ì¥
    save_regions_to_db(scraped_regions)
